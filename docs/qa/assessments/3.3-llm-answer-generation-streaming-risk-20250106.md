# 风险评估报告: Story 3.3 - LLM回答生成与流式输出

**日期**: 2025-01-06  
**评审人**: Quinn (Test Architect)  
**Story**: 3.3 - LLM回答生成与流式输出  
**Epic**: 3 - 智能问答与引用系统

---

## 执行摘要

- **总识别风险数**: 15
- **关键风险**: 3 (分数 9)
- **高风险**: 4 (分数 6)
- **中等风险**: 6 (分数 4)
- **低风险**: 2 (分数 2-3)
- **风险评分**: 62/100

### 关键发现

本Story是MVP的核心功能，涉及多个第三方LLM服务、复杂的流式响应机制和对话管理。主要风险集中在:
1. **LLM服务依赖** - 单点故障和成本控制
2. **回答质量** - 准确率目标(85%)具有挑战性
3. **流式响应稳定性** - 涉及复杂的异步处理

---

## 关键风险需要立即关注

### 1. [SEC-001]: LLM Prompt注入攻击

**风险评分: 9 (关键)**
- **概率**: High (3) - Prompt注入是LLM应用的已知攻击向量
- **影响**: High (3) - 可能导致系统生成不当内容、绕过限制或泄露敏感信息

**详细描述**:
用户可能通过精心设计的输入绕过System Prompt指令，导致:
- 忽略"只使用文档内容"的限制
- 生成有害或不当内容
- 泄露System Prompt内容
- 绕过引用标注要求

**受影响组件**:
- `src/services/rag/promptBuilder.ts` - Prompt构建
- `src/services/rag/answerService.ts` - LLM调用
- `src/app/api/chat/query/route.ts` - 输入验证

**缓解策略**:
- **输入验证和清理**: 在API层实施严格的输入验证
  - 限制特殊字符和控制字符
  - 检测和拒绝可疑的Prompt注入模式
  - 最大长度限制（1000字符）
- **Prompt加固**: 
  - 在System Prompt中明确禁止忽略指令的行为
  - 使用分隔符明确区分指令和用户输入
  - 添加"输出格式验证"指令
- **输出过滤**: 
  - 检测回答中的异常模式（如"忽略之前的指令"）
  - 验证引用标记格式
  - 内容安全过滤（敏感信息、不当内容）
- **监控和告警**:
  - 记录所有可疑输入
  - 设置异常检测规则
  - 人工审核标记的问题案例

**测试要求**:
- 安全测试: 测试常见Prompt注入攻击模式
- 单元测试: `promptBuilder.sanitizeInput()`
- 集成测试: 端到端注入攻击场景
- 渗透测试: 聘请安全专家进行评估

**剩余风险**: 中等 - 即使采取措施，仍可能存在未知的绕过方法

---

### 2. [BUS-001]: 问答准确率低于目标(85%)

**风险评分: 9 (关键)**
- **概率**: High (3) - RAG系统准确率受多因素影响，达到85%具有挑战性
- **影响**: High (3) - 直接影响MVP交付和用户满意度

**详细描述**:
问答准确率是MVP的核心质量指标。如果准确率低于85%:
- 用户体验差，留存率低
- MVP交付延期
- 需要大量迭代优化

**影响准确率的因素**:
1. **检索质量**: 向量检索是否返回相关内容
2. **Prompt质量**: System Prompt是否清晰有效
3. **LLM能力**: 不同模型的理解和生成能力差异
4. **上下文控制**: Token限制是否导致关键信息丢失
5. **问题复杂度**: 复杂问题需要深度推理

**缓解策略**:
- **分阶段优化**:
  1. **基线测试** (第1周): 
     - 准备20个代表性测试问题
     - 测试初始准确率
     - 识别主要失败模式
  2. **检索优化** (第2周):
     - 调整Top-K参数
     - 优化相似度阈值
     - 测试不同的分块策略
  3. **Prompt优化** (第3周):
     - A/B测试不同Prompt版本
     - 优化指令措辞
     - 调整上下文格式
  4. **模型优化** (第4周):
     - 测试不同LLM模型
     - 优化temperature参数
     - 调整maxTokens设置
  
- **质量评估流程**:
  - 每周执行质量评估
  - 记录失败案例和原因
  - 持续迭代优化
  - 目标每周提升5-10%
  
- **应急方案**:
  - 如果4周内无法达到85%，考虑:
    - 降低MVP目标到80%
    - 增加人工审核环节
    - 延期交付进行更多优化

**测试要求**:
- 质量评估测试: `docs/qa/3.3-manual-quality-assessment.md`
- 准备多样化测试集（不同文档类型、问题类型）
- 人工评分标准和流程
- 持续监控和优化

**剩余风险**: 中高 - 需要持续优化和监控

---

### 3. [PERF-001]: LLM首字节响应时间超过3秒

**风险评分: 9 (关键)**
- **概率**: High (3) - LLM API调用延迟不可控，受多因素影响
- **影响**: High (3) - 直接影响用户体验和MVP性能目标

**详细描述**:
首字节响应时间(TTFB)是流式体验的关键指标。超过3秒会导致:
- 用户感觉系统"卡住"
- 用户放弃查询
- 性能目标未达成

**影响TTFB的因素**:
1. **检索延迟**: Story 3.2的向量检索时间
2. **Prompt构建**: 上下文格式化和历史查询
3. **LLM API延迟**: 不同提供商和模型的冷启动时间
4. **网络延迟**: 部署区域和API端点的距离

**缓解策略**:
- **并行优化**:
  - 检索和对话历史查询并行执行
  - Prompt构建异步进行
  - 减少串行等待时间
  
- **LLM选择优化**:
  - 优先选择响应快的模型(如Gemini Flash)
  - 国内部署使用智谱AI（延迟更低）
  - 设置合理的timeout (5秒)
  
- **缓存策略**:
  - 常见问题答案缓存（Redis）
  - 缓存键: `answer:${documentId}:${questionHash}`
  - TTL: 1小时
  - 命中率目标: 20-30%
  
- **流式优化**:
  - 确保首个chunk尽快发送
  - 减少前置阻塞操作
  - 异步执行非关键任务（日志、统计）
  
- **降级策略**:
  - 如果主LLM超时→立即切换到备用
  - 显示"正在生成回答..."加载提示
  - 超过10秒返回超时错误

**测试要求**:
- 性能测试: `tests/performance/llm-streaming.benchmark.ts`
- 监控P50, P95, P99延迟
- 测试不同LLM提供商的延迟分布
- 负载测试（并发10个请求）

**剩余风险**: 中等 - 第三方API延迟不可完全控制

---

## 风险分布

### 按类别

| 类别 | 关键 | 高 | 中 | 低 | 总计 |
|------|------|----|----|----|----|
| 安全 (SEC) | 1 | 1 | 0 | 0 | 2 |
| 性能 (PERF) | 1 | 1 | 2 | 1 | 5 |
| 数据 (DATA) | 0 | 1 | 2 | 0 | 3 |
| 业务 (BUS) | 1 | 0 | 1 | 0 | 2 |
| 技术 (TECH) | 0 | 1 | 1 | 1 | 3 |

### 按组件

| 组件 | 关键风险 | 高风险 | 中风险 |
|------|---------|--------|--------|
| LLM回答生成服务 | 2 | 1 | 2 |
| 流式响应机制 | 1 | 2 | 1 |
| 对话持久化 | 0 | 1 | 2 |
| 使用量统计 | 0 | 0 | 1 |

---

## 详细风险清单

### 安全风险 (SEC)

| ID | 风险 | 概率 | 影响 | 评分 | 缓解措施 |
|---|------|------|------|------|---------|
| SEC-001 | Prompt注入攻击 | High | High | 9 | 输入验证、Prompt加固、输出过滤 |
| SEC-002 | LLM API密钥泄露 | Medium | High | 6 | 环境变量、Secrets管理、定期轮换 |

### 性能风险 (PERF)

| ID | 风险 | 概率 | 影响 | 评分 | 缓解措施 |
|---|------|------|------|------|---------|
| PERF-001 | 首字节响应超过3秒 | High | High | 9 | 并行优化、缓存、LLM选择 |
| PERF-002 | 流式响应中断频繁 | Medium | High | 6 | 错误重试、连接保活、超时处理 |
| PERF-003 | 并发处理能力不足 | Medium | Medium | 4 | 连接池、异步处理、限流 |
| PERF-004 | 完整回答时间超过10秒 | Medium | Medium | 4 | Token限制、模型选择、流式优化 |
| PERF-005 | 数据库写入延迟 | Low | Low | 1 | 异步写入、批量操作 |

### 数据风险 (DATA)

| ID | 风险 | 概率 | 影响 | 评分 | 缓解措施 |
|---|------|------|------|------|---------|
| DATA-001 | 对话数据丢失 | Medium | High | 6 | 事务处理、错误重试、备份 |
| DATA-002 | 引用数据不一致 | Medium | Medium | 4 | 数据验证、完整性约束 |
| DATA-003 | 使用量统计不准确 | Medium | Medium | 4 | 异步降级、定期校准 |

### 业务风险 (BUS)

| ID | 风险 | 概率 | 影响 | 评分 | 缓解措施 |
|---|------|------|------|------|---------|
| BUS-001 | 问答准确率低于85% | High | High | 9 | 分阶段优化、质量评估流程 |
| BUS-002 | LLM成本超预算 | Medium | Medium | 4 | 智能路由、缓存、监控告警 |

### 技术风险 (TECH)

| ID | 风险 | 概率 | 影响 | 评分 | 缓解措施 |
|---|------|------|------|------|---------|
| TECH-001 | LLM API单点故障 | Medium | High | 6 | 多提供商降级、健康检查 |
| TECH-002 | 多轮对话上下文管理复杂 | Medium | Medium | 4 | 限制历史轮次、Token控制 |
| TECH-003 | 智能路由逻辑失效 | Low | Medium | 2 | 降级到默认模型、监控 |

---

## 风险缓解优先级

### 必须在实现前解决 (关键风险)

1. **SEC-001 - Prompt注入防护**
   - 实施输入验证和清理
   - 加固System Prompt
   - 添加输出过滤
   - 预计工时: 4小时

2. **BUS-001 - 准确率评估计划**
   - 准备测试问题集
   - 建立评估流程
   - 制定优化路线图
   - 预计工时: 8小时

3. **PERF-001 - 性能优化**
   - 实施并行处理
   - 配置缓存
   - LLM选择优化
   - 预计工时: 6小时

### 必须在部署前验证 (高风险)

4. **SEC-002 - API密钥管理**
5. **PERF-002 - 流式稳定性测试**
6. **DATA-001 - 对话数据可靠性**
7. **TECH-001 - 多提供商降级测试**

### 持续监控和优化 (中等风险)

8. **PERF-003/004 - 性能持续优化**
9. **DATA-002/003 - 数据质量监控**
10. **BUS-002 - 成本监控**
11. **TECH-002 - 上下文管理优化**

---

## 基于风险的测试策略

### 优先级1: 关键风险测试

**安全测试**:
- Prompt注入攻击场景（20+测试用例）
- API密钥泄露检测
- 输出内容安全检查
- 渗透测试（外部专家）

**质量评估测试**:
- 准备多样化问题集（20个问题）
- 人工评分流程
- 准确率计算方法
- 每周评估和优化

**性能压力测试**:
- 首字节延迟测试（P95 < 3秒）
- 流式响应稳定性（并发10个）
- 超时和重试场景
- 不同LLM提供商对比

### 优先级2: 高风险测试

**数据可靠性测试**:
- 对话保存失败恢复
- 流式中断时数据状态
- 并发写入冲突
- 事务回滚测试

**降级策略测试**:
- 主LLM失败→备用LLM
- API超时处理
- 配额超限处理
- 健康检查机制

### 优先级3: 中低风险测试

**功能完整性测试**:
- 多轮对话上下文保持
- 使用量统计准确性
- 缓存命中和失效
- 智能路由决策

---

## 风险接受标准

### 必须修复才能部署

- 任何评分≥9的关键风险
- SEC-001: Prompt注入防护必须实施
- BUS-001: 准确率必须≥80%（最低接受标准）
- PERF-001: 首字节延迟必须<5秒（降级标准）

### 可以带缓解措施部署

- 评分=6的高风险（有监控和补偿控制）
- PERF-002: 流式中断<5%
- DATA-001: 对话丢失<0.1%
- TECH-001: 降级机制验证通过

### 接受的风险

- 评分≤4的中低风险
- TECH-003: 智能路由失效（可降级到默认模型）
- PERF-005: 数据库写入延迟（已异步化）

---

## 部署后监控要求

### 关键指标（实时告警）

1. **性能指标**:
   - 首字节延迟 (P50, P95, P99)
   - 完整回答延迟
   - 流式响应成功率
   - LLM API延迟分布

2. **质量指标**:
   - 问答准确率（用户反馈）
   - 错误率和类型分布
   - 降级触发频率
   - 缓存命中率

3. **成本指标**:
   - LLM API调用量
   - Token消耗统计
   - 单次查询成本
   - 月度成本趋势

4. **安全指标**:
   - 可疑输入检测
   - Prompt注入尝试
   - API密钥异常使用
   - 输出内容异常

### 告警阈值

- 首字节延迟 P95 > 5秒 → 警告
- 流式响应失败率 > 2% → 警告
- 准确率 < 80% → 严重
- LLM API失败率 > 5% → 警告
- 日成本超预算20% → 警告

---

## 风险评审触发条件

重新评估和更新风险档案的时机:

1. **架构重大变更** - LLM提供商变更、流式机制调整
2. **性能问题报告** - 首字节延迟或完整延迟超标
3. **准确率低于预期** - 质量评估不达标
4. **成本异常** - LLM费用超预算
5. **安全事件** - Prompt注入攻击成功
6. **定期评审** - 每月一次风险回顾

---

## 总结和建议

### 整体风险评估

Story 3.3是MVP的核心和最复杂的功能，风险评分62/100（中高风险）。主要风险来自:
1. 第三方LLM服务依赖
2. 质量目标(85%准确率)的挑战性
3. 流式响应的技术复杂度

### 关键行动项

**实施前必须完成**:
1. ✅ Prompt注入防护实施和测试
2. ✅ 质量评估流程建立
3. ✅ 性能优化（并行、缓存）

**部署前必须验证**:
4. ✅ 准确率≥80%（最低标准）
5. ✅ 首字节延迟<5秒（降级标准）
6. ✅ 多提供商降级测试通过
7. ✅ 数据可靠性测试通过

**部署后持续监控**:
8. ✅ 实时性能和质量监控
9. ✅ 成本追踪和告警
10. ✅ 安全事件检测

### 成功关键因素

1. **迭代优化**: 准确率提升是渐进的，需要4周持续优化
2. **多提供商策略**: 确保高可用性和成本优化
3. **全面测试**: 安全、性能、质量三位一体
4. **主动监控**: 部署后快速发现和响应问题

### 风险接受建议

建议团队接受以下权衡:
- 准确率目标可从85%降至80%（首个版本）
- 首字节延迟目标可从3秒降至5秒（P95）
- 通过迭代优化逐步达到理想目标

---

**下次评审日期**: 2025-01-20（部署后2周）  
**风险负责人**: Quinn (Test Architect)  
**批准人**: _待定_

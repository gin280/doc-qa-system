# Test Design: Story 4.5

**Story**: 4.5 - 边界情况处理增强  
**Date**: 2025-01-14  
**Designer**: Quinn (测试架构师)

---

## Test Strategy Overview

- **Total test scenarios**: 23
- **Unit tests**: 14 (61%)
- **Integration tests**: 9 (39%)
- **E2E tests**: 0 (0%)
- **Priority distribution**: 
  - P0: 16 (70%) - 关键边界处理
  - P1: 5 (22%) - Unicode 和日志
  - P2: 2 (8%) - 边界值验证

**测试策略**:
- ✅ **Shift-left approach**: 主要依赖单元测试快速验证边界逻辑
- ✅ **Integration tests**: 验证端到端错误处理流程和数据库状态
- ✅ **No E2E tests**: 边界处理属于服务层逻辑，无需 UI 测试
- ✅ **Risk-based prioritization**: 高风险场景标记为 P0

---

## Test Scenarios by Acceptance Criteria

### AC1: 空文档检测和处理

**需求**: 检测内容长度为 0 或仅包含空白字符，抛出友好错误并设置 FAILED 状态

**风险覆盖**: DATA-001 (分数 4)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-001 | Unit | P0 | 完全空文档抛出错误 | 纯逻辑验证，无依赖 | DATA-001 |
| 4.5-UNIT-002 | Unit | P0 | 错误消息为 "文档内容为空，无法处理" | 验证错误消息友好性 | DATA-001 |
| 4.5-INT-001 | Integration | P0 | 空文档端到端流程设置 FAILED 状态 | 验证数据库状态变更 | DATA-001 |
| 4.5-INT-002 | Integration | P0 | metadata 包含 EMPTY_CONTENT 错误类型 | 验证错误记录完整性 | DATA-001 |

**测试数据**:
- 空字符串: `''`
- Null: `null`
- Undefined: `undefined`

**预期行为**:
- 抛出 `ChunkingError`
- 错误消息: "文档内容为空，无法处理"
- 文档状态: FAILED
- Metadata: `{ errorType: 'EMPTY_CONTENT' }`

---

### AC2: 空白字符文档检测

**需求**: 检测仅包含空白字符（空格、换行、制表符）的文档，使用 trim() 后检查长度

**风险覆盖**: DATA-001 (分数 4)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-003 | Unit | P0 | 仅空格文档抛出错误 | 验证 trim() 逻辑 | DATA-001 |
| 4.5-UNIT-004 | Unit | P0 | 仅换行符文档抛出错误 | 边界情况验证 | DATA-001 |
| 4.5-UNIT-005 | Unit | P0 | 混合空白字符文档抛出错误 | 综合空白字符测试 | DATA-001 |
| 4.5-INT-003 | Integration | P0 | 空白文档端到端返回友好错误 | 用户体验验证 | DATA-001 |

**测试数据**:
- 仅空格: `'   '` (3个空格)
- 仅换行: `'\n\n\n'`
- 仅制表符: `'\t\t\t'`
- 混合: `' \n\t \n '`

**预期行为**:
- 与 AC1 相同的错误处理
- trim() 后长度为 0

---

### AC3: 超大文档限制

**需求**: 定义 MAX_CHUNKS = 10000，超过时截断并记录告警，在 metadata 中标记

**风险覆盖**: PERF-001 (分数 6, HIGH)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-006 | Unit | P0 | 超过 10000 chunks 时截断到 10000 | 核心截断逻辑 | PERF-001 |
| 4.5-UNIT-007 | Unit | P0 | 截断时记录 WARN 日志 | 验证日志级别和内容 | PERF-001, OPS-001 |
| 4.5-UNIT-008 | Unit | P2 | 恰好 10000 chunks 不截断 | 边界值测试 | PERF-001 |
| 4.5-UNIT-009 | Unit | P2 | 9999 chunks 不截断 | 边界值测试（临界值下） | PERF-001 |
| 4.5-INT-004 | Integration | P0 | 截断后 metadata 包含完整信息 | 验证数据完整性 | PERF-001, DATA-003 |
| 4.5-INT-005 | Integration | P0 | 超大文档端到端成功处理 | 验证不会导致系统崩溃 | PERF-001 |

**测试数据**:
- 超限文档: 15000 chunks (模拟 50MB PDF)
- 边界文档: 10000 chunks
- 临界文档: 9999 chunks

**预期行为**:
- **15000 chunks**:
  - 截断到 10000
  - WARN 日志包含: `{ documentId, originalChunksCount: 15000, maxChunks: 10000 }`
  - Metadata: `{ chunking: { truncated: true, originalChunksCount: 15000, storedChunksCount: 10000 } }`
- **10000 chunks**: 不截断，无告警
- **9999 chunks**: 不截断，无告警

---

### AC4: 向量维度验证

**需求**: 在 embedding 生成后验证维度，ZhipuAI 1024, OpenAI 1536，不匹配时抛出 DIMENSION_MISMATCH

**风险覆盖**: DATA-002 (分数 3)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-010 | Unit | P0 | ZhipuAI 向量维度 1024 通过验证 | 验证正确维度 | DATA-002 |
| 4.5-UNIT-011 | Unit | P0 | ZhipuAI 向量维度 1536 抛出错误 | 验证错误维度检测 | DATA-002 |
| 4.5-UNIT-012 | Unit | P0 | OpenAI 向量维度 1536 通过验证 | 验证正确维度 | DATA-002 |
| 4.5-UNIT-013 | Unit | P0 | OpenAI 向量维度 1024 抛出错误 | 验证错误维度检测 | DATA-002 |
| 4.5-UNIT-014 | Unit | P0 | 维度不匹配记录 ERROR 日志 | 验证日志记录 | DATA-002, OPS-001 |

**测试数据** (Mock):
- ZhipuAI provider:
  - 正确: 1024 维向量
  - 错误: 1536 维向量
- OpenAI provider:
  - 正确: 1536 维向量
  - 错误: 1024 维向量

**预期行为**:
- **维度正确**: 继续处理，无异常
- **维度不匹配**:
  - 抛出 `EmbeddingError` (type: 'DIMENSION_MISMATCH')
  - 错误消息: `Vector dimension mismatch: expected {expected}, got {actual}`
  - ERROR 日志包含: `{ documentId, chunkId, expectedDimension, actualDimension, provider }`

---

### AC5: Unicode 特殊字符处理

**需求**: 验证分块器正确处理中文、Emoji、混合特殊符号

**风险覆盖**: TECH-001 (分数 2)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-INT-006 | Integration | P1 | 纯中文文档正确分块 | 验证中文字符支持 | TECH-001 |
| 4.5-INT-007 | Integration | P1 | Emoji 文档正确分块 | 验证 Emoji 支持 | TECH-001 |
| 4.5-INT-008 | Integration | P1 | 中英文混合文档正确分块 | 验证混合字符集 | TECH-001 |
| 4.5-INT-009 | Integration | P1 | 特殊符号文档正确分块 | 验证符号支持 | TECH-001 |

**测试数据**:
- **纯中文**: "这是一个测试文档。内容包含完整的中文句子。" × 100
- **Emoji**: "Hello 👋 World 🌍 Test 🚀 Document 📄" × 100
- **混合**: "Price: €100, 版权 Copyright ©2025, 喜欢 Love ♥" × 100
- **特殊符号**: "™ ® © € £ ¥ ± × ÷ ≠ ≤ ≥" × 100

**预期行为**:
- 分块成功，无异常
- Chunks 内容保留完整的 Unicode 字符
- 字符不被损坏或替换
- 向量化成功

**注意**: 这些是集成测试，因为需要验证整个流程（解析 → 分块 → 向量化）

---

### AC6: 错误日志结构化

**需求**: 所有错误日志包含标准字段 (timestamp, documentId, errorType, message, context)

**风险覆盖**: OPS-001 (分数 4)

#### Scenarios

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-015 | Unit | P1 | ChunkingError 日志包含标准字段 | 验证日志结构 | OPS-001 |
| 4.5-UNIT-016 | Unit | P1 | EmbeddingError 日志包含标准字段 | 验证日志结构 | OPS-001 |

**验证字段**:
```typescript
{
  timestamp: string,        // ISO-8601 格式
  documentId: string,       // 文档 ID
  errorType: string,        // 错误类型枚举
  message: string,          // 错误消息
  context: {                // 上下文信息
    // 相关参数
  }
}
```

**预期行为**:
- 所有错误日志使用 `console.error('[Service] 错误:', structuredLog)`
- 所有告警日志使用 `console.warn('[Service] 告警:', structuredLog)`
- 字段完整且类型正确

---

### AC7: 错误状态和恢复

**需求**: FAILED 状态的文档在 metadata 中包含完整错误信息，错误类型可区分

**风险覆盖**: DATA-001, DATA-002, OPS-001 (综合)

**注意**: 此 AC 的测试已在 AC1-AC6 中覆盖，无需额外测试场景

**验证点**:
- AC1, AC2 的集成测试已验证 `EMPTY_CONTENT` 错误类型
- AC3 的集成测试已验证截断信息记录
- AC4 的单元测试已验证 `DIMENSION_MISMATCH` 错误类型
- 所有集成测试验证 metadata 完整性

---

## Risk Coverage Matrix

将测试场景映射到已识别的风险：

| 风险 ID | 风险标题 | 分数 | 测试场景 | 覆盖率 |
|---------|----------|------|----------|--------|
| PERF-001 | 超大文档未截断 | 6 | 4.5-UNIT-006, 007, 008, 009<br>4.5-INT-004, 005 | ✅ 完全覆盖 |
| DATA-001 | 空文档检测不完整 | 4 | 4.5-UNIT-001, 002, 003, 004, 005<br>4.5-INT-001, 002, 003 | ✅ 完全覆盖 |
| OPS-001 | 错误日志不结构化 | 4 | 4.5-UNIT-007, 014, 015, 016 | ✅ 完全覆盖 |
| DATA-003 | 截断后用户不知情 | 4 | 4.5-INT-004 | ⚠️ 部分覆盖* |
| DATA-002 | 维度不匹配 | 3 | 4.5-UNIT-010, 011, 012, 013, 014 | ✅ 完全覆盖 |
| TECH-001 | Unicode 处理错误 | 2 | 4.5-INT-006, 007, 008, 009 | ✅ 完全覆盖 |

**注**: 
- *DATA-003 的 UI 显示部分不在此 Story 范围内，metadata 记录已覆盖

**风险缓解率**: 100% (所有识别的风险都有对应测试)

---

## Test Scenarios Summary Table

| ID | AC | Level | Priority | Test Description | Mitigates Risk |
|----|----|----|----------|------------------|----------------|
| 4.5-UNIT-001 | AC1 | Unit | P0 | 完全空文档抛出错误 | DATA-001 |
| 4.5-UNIT-002 | AC1 | Unit | P0 | 错误消息为 "文档内容为空，无法处理" | DATA-001 |
| 4.5-UNIT-003 | AC2 | Unit | P0 | 仅空格文档抛出错误 | DATA-001 |
| 4.5-UNIT-004 | AC2 | Unit | P0 | 仅换行符文档抛出错误 | DATA-001 |
| 4.5-UNIT-005 | AC2 | Unit | P0 | 混合空白字符文档抛出错误 | DATA-001 |
| 4.5-UNIT-006 | AC3 | Unit | P0 | 超过 10000 chunks 时截断到 10000 | PERF-001 |
| 4.5-UNIT-007 | AC3 | Unit | P0 | 截断时记录 WARN 日志 | PERF-001, OPS-001 |
| 4.5-UNIT-008 | AC3 | Unit | P2 | 恰好 10000 chunks 不截断 | PERF-001 |
| 4.5-UNIT-009 | AC3 | Unit | P2 | 9999 chunks 不截断 | PERF-001 |
| 4.5-UNIT-010 | AC4 | Unit | P0 | ZhipuAI 向量维度 1024 通过验证 | DATA-002 |
| 4.5-UNIT-011 | AC4 | Unit | P0 | ZhipuAI 向量维度 1536 抛出错误 | DATA-002 |
| 4.5-UNIT-012 | AC4 | Unit | P0 | OpenAI 向量维度 1536 通过验证 | DATA-002 |
| 4.5-UNIT-013 | AC4 | Unit | P0 | OpenAI 向量维度 1024 抛出错误 | DATA-002 |
| 4.5-UNIT-014 | AC4 | Unit | P0 | 维度不匹配记录 ERROR 日志 | DATA-002, OPS-001 |
| 4.5-UNIT-015 | AC6 | Unit | P1 | ChunkingError 日志包含标准字段 | OPS-001 |
| 4.5-UNIT-016 | AC6 | Unit | P1 | EmbeddingError 日志包含标准字段 | OPS-001 |
| 4.5-INT-001 | AC1 | Integration | P0 | 空文档端到端流程设置 FAILED 状态 | DATA-001 |
| 4.5-INT-002 | AC1 | Integration | P0 | metadata 包含 EMPTY_CONTENT 错误类型 | DATA-001 |
| 4.5-INT-003 | AC2 | Integration | P0 | 空白文档端到端返回友好错误 | DATA-001 |
| 4.5-INT-004 | AC3 | Integration | P0 | 截断后 metadata 包含完整信息 | PERF-001, DATA-003 |
| 4.5-INT-005 | AC3 | Integration | P0 | 超大文档端到端成功处理 | PERF-001 |
| 4.5-INT-006 | AC5 | Integration | P1 | 纯中文文档正确分块 | TECH-001 |
| 4.5-INT-007 | AC5 | Integration | P1 | Emoji 文档正确分块 | TECH-001 |
| 4.5-INT-008 | AC5 | Integration | P1 | 中英文混合文档正确分块 | TECH-001 |
| 4.5-INT-009 | AC5 | Integration | P1 | 特殊符号文档正确分块 | TECH-001 |

---

## Recommended Execution Order

### Phase 1: P0 Unit Tests (Fast Feedback)

**执行时间**: ~5 分钟  
**测试数**: 14 个

```bash
npm test tests/unit/services/documents/chunkingService.test.ts
npm test tests/unit/services/documents/embeddingService.test.ts
```

**包含测试**:
- 4.5-UNIT-001 到 4.5-UNIT-014

**目的**: 快速验证核心逻辑，如果失败立即停止

---

### Phase 2: P0 Integration Tests (Critical Paths)

**执行时间**: ~3 分钟  
**测试数**: 7 个

```bash
npm run test:integration tests/integration/documents/edge-cases.test.ts
```

**包含测试**:
- 4.5-INT-001, 002, 003 (空文档端到端)
- 4.5-INT-004, 005 (超大文档端到端)

**目的**: 验证端到端流程和数据库状态

---

### Phase 3: P1 Tests (Important Coverage)

**执行时间**: ~4 分钟  
**测试数**: 6 个

```bash
# 单元测试
npm test tests/unit/services/documents/ -- --testNamePattern="日志"

# 集成测试
npm run test:integration tests/integration/documents/unicode-handling.test.ts
```

**包含测试**:
- 4.5-UNIT-015, 016 (日志结构化)
- 4.5-INT-006, 007, 008, 009 (Unicode 处理)

**目的**: 验证日志和 Unicode 支持

---

### Phase 4: P2 Tests (Edge Cases)

**执行时间**: ~1 分钟  
**测试数**: 2 个

```bash
npm test tests/unit/services/documents/chunkingService.test.ts -- --testNamePattern="边界"
```

**包含测试**:
- 4.5-UNIT-008 (恰好 10000 chunks)
- 4.5-UNIT-009 (9999 chunks)

**目的**: 边界值验证

---

## Test Implementation Guide

### Unit Test File Structure

**文件**: `tests/unit/services/documents/chunkingService.test.ts`

```typescript
describe('ChunkingService - Edge Cases', () => {
  describe('AC1 & AC2: 空文档检测', () => {
    it('4.5-UNIT-001: 应该在完全空文档时抛出错误', async () => {
      // Arrange
      const emptyContent = ''
      
      // Act & Assert
      await expect(chunkingService.chunkDocument(documentId, emptyContent))
        .rejects
        .toThrow('文档内容为空，无法处理')
    })
    
    it('4.5-UNIT-003: 应该在仅空格文档时抛出错误', async () => {
      const whitespaceContent = '   '
      await expect(chunkingService.chunkDocument(documentId, whitespaceContent))
        .rejects
        .toThrow('文档内容为空，无法处理')
    })
    
    // ... 其他测试
  })
  
  describe('AC3: 超大文档限制', () => {
    it('4.5-UNIT-006: 应该在超过 10000 chunks 时截断', async () => {
      // Arrange
      const largeContent = 'x'.repeat(5000000) // 产生 ~15000 chunks
      const consoleWarnSpy = jest.spyOn(console, 'warn')
      
      // Act
      const result = await chunkingService.chunkDocument(documentId, largeContent)
      
      // Assert
      expect(result.chunks.length).toBe(10000)
      expect(consoleWarnSpy).toHaveBeenCalledWith(
        expect.stringContaining('[Chunking] 文档超过最大chunks限制'),
        expect.objectContaining({
          documentId,
          maxChunks: 10000
        })
      )
    })
    
    it('4.5-UNIT-008: 应该在恰好 10000 chunks 时不截断', async () => {
      // Arrange - 精确控制内容产生恰好 10000 chunks
      const exactContent = generateExactChunks(10000)
      const consoleWarnSpy = jest.spyOn(console, 'warn')
      
      // Act
      const result = await chunkingService.chunkDocument(documentId, exactContent)
      
      // Assert
      expect(result.chunks.length).toBe(10000)
      expect(consoleWarnSpy).not.toHaveBeenCalled()
    })
    
    // ... 其他测试
  })
})
```

---

**文件**: `tests/unit/services/documents/embeddingService.test.ts`

```typescript
describe('EmbeddingService - Dimension Validation', () => {
  describe('AC4: 向量维度验证', () => {
    it('4.5-UNIT-010: 应该验证 ZhipuAI 1024 维向量通过', async () => {
      // Arrange
      mockLLMConfig.provider = 'zhipu'
      const mockVector = new Array(1024).fill(0.1)
      mockLLM.generateEmbeddings.mockResolvedValue([mockVector])
      
      // Act & Assert
      await expect(embeddingService.embedAndStoreChunks(chunks))
        .resolves
        .not.toThrow()
    })
    
    it('4.5-UNIT-011: 应该在 ZhipuAI 返回 1536 维向量时抛出错误', async () => {
      // Arrange
      mockLLMConfig.provider = 'zhipu'
      const wrongVector = new Array(1536).fill(0.1) // 错误维度
      mockLLM.generateEmbeddings.mockResolvedValue([wrongVector])
      
      // Act & Assert
      await expect(embeddingService.embedAndStoreChunks(chunks))
        .rejects
        .toThrow(EmbeddingError)
      
      await expect(embeddingService.embedAndStoreChunks(chunks))
        .rejects
        .toThrow('Vector dimension mismatch: expected 1024, got 1536')
    })
    
    // ... 其他测试
  })
})
```

---

### Integration Test File Structure

**文件**: `tests/integration/documents/edge-cases.test.ts`

```typescript
describe('Edge Cases - Integration Tests', () => {
  describe('AC1 & AC2: 空文档端到端处理', () => {
    it('4.5-INT-001: 空文档应设置 FAILED 状态', async () => {
      // Arrange
      const emptyFile = createTestFile('empty.txt', '')
      
      // Act
      const response = await uploadDocument(emptyFile)
      
      // Assert - API 返回错误
      expect(response.status).toBe(400)
      expect(response.body.error).toContain('文档内容为空')
      
      // Assert - 数据库状态
      const doc = await db.query.documents.findFirst({
        where: eq(documents.id, response.body.documentId)
      })
      expect(doc.status).toBe('FAILED')
      expect(doc.metadata.errorType).toBe('EMPTY_CONTENT')
    })
    
    it('4.5-INT-003: 空白文档应返回友好错误', async () => {
      const whitespaceFile = createTestFile('whitespace.txt', '   \n\t  ')
      const response = await uploadDocument(whitespaceFile)
      
      expect(response.status).toBe(400)
      expect(response.body.error).toBe('文档内容为空，无法处理')
    })
  })
  
  describe('AC3: 超大文档端到端处理', () => {
    it('4.5-INT-004: 截断后 metadata 包含完整信息', async () => {
      // Arrange - 生成超大测试文件
      const largeFile = await generateLargeTestFile(15000) // 15000 chunks
      
      // Act
      const response = await uploadDocument(largeFile)
      
      // Assert
      expect(response.status).toBe(200)
      
      const doc = await db.query.documents.findFirst({
        where: eq(documents.id, response.body.documentId)
      })
      
      expect(doc.status).toBe('COMPLETED')
      expect(doc.metadata.chunking).toEqual({
        truncated: true,
        originalChunksCount: 15000,
        storedChunksCount: 10000
      })
      
      // Verify only 10000 chunks stored
      const chunks = await db.query.documentChunks.findMany({
        where: eq(documentChunks.documentId, doc.id)
      })
      expect(chunks.length).toBe(10000)
    })
    
    it('4.5-INT-005: 超大文档应成功处理不崩溃', async () => {
      const largeFile = await generateLargeTestFile(15000)
      
      // Act - 应该在合理时间内完成
      const startTime = Date.now()
      const response = await uploadDocument(largeFile)
      const duration = Date.now() - startTime
      
      // Assert
      expect(response.status).toBe(200)
      expect(duration).toBeLessThan(300000) // < 5 分钟
    })
  })
})
```

---

**文件**: `tests/integration/documents/unicode-handling.test.ts`

```typescript
describe('Unicode Handling - Integration Tests', () => {
  describe('AC5: Unicode 特殊字符处理', () => {
    it('4.5-INT-006: 应该正确处理纯中文文档', async () => {
      // Arrange
      const chineseContent = '这是一个测试文档。内容包含完整的中文句子。'.repeat(100)
      const chineseFile = createTestFile('chinese.txt', chineseContent)
      
      // Act
      const response = await uploadDocument(chineseFile)
      
      // Assert
      expect(response.status).toBe(200)
      
      // Verify chunks preserved Chinese characters
      const chunks = await getDocumentChunks(response.body.documentId)
      expect(chunks[0].content).toMatch(/[\u4e00-\u9fa5]/) // 包含中文
      expect(chunks[0].content).not.toContain('�') // 无乱码
    })
    
    it('4.5-INT-007: 应该正确处理 Emoji 文档', async () => {
      const emojiContent = 'Hello 👋 World 🌍 Test 🚀 Document 📄'.repeat(100)
      const emojiFile = createTestFile('emoji.txt', emojiContent)
      
      const response = await uploadDocument(emojiFile)
      expect(response.status).toBe(200)
      
      const chunks = await getDocumentChunks(response.body.documentId)
      expect(chunks[0].content).toMatch(/👋|🌍|🚀|📄/)
    })
    
    it('4.5-INT-008: 应该正确处理中英文混合文档', async () => {
      const mixedContent = 'Price: €100, 版权 Copyright ©2025, 喜欢 Love ♥'.repeat(100)
      const mixedFile = createTestFile('mixed.txt', mixedContent)
      
      const response = await uploadDocument(mixedFile)
      expect(response.status).toBe(200)
      
      const chunks = await getDocumentChunks(response.body.documentId)
      expect(chunks[0].content).toMatch(/版权/)
      expect(chunks[0].content).toMatch(/€|©|♥/)
    })
    
    it('4.5-INT-009: 应该正确处理特殊符号文档', async () => {
      const symbolContent = '™ ® © € £ ¥ ± × ÷ ≠ ≤ ≥'.repeat(100)
      const symbolFile = createTestFile('symbols.txt', symbolContent)
      
      const response = await uploadDocument(symbolFile)
      expect(response.status).toBe(200)
    })
  })
})
```

---

## Test Data Generation

### Helper Functions

```typescript
// tests/helpers/testDataGenerator.ts

/**
 * 生成恰好指定数量 chunks 的文本内容
 * @param chunkCount 期望的 chunks 数量
 * @param chunkSize 每个 chunk 的大小（默认 500）
 * @param overlap 重叠大小（默认 50）
 */
export function generateExactChunks(
  chunkCount: number, 
  chunkSize: number = 500, 
  overlap: number = 50
): string {
  // 计算需要的总字符数
  // 公式: totalChars = chunkSize + (chunkCount - 1) * (chunkSize - overlap)
  const totalChars = chunkSize + (chunkCount - 1) * (chunkSize - overlap)
  
  // 生成有意义的测试文本
  const sentence = '这是一个测试句子用于生成大量文本内容。'
  const content = sentence.repeat(Math.ceil(totalChars / sentence.length))
  
  return content.slice(0, totalChars)
}

/**
 * 生成超大测试文件
 * @param chunkCount 期望产生的 chunks 数量
 */
export async function generateLargeTestFile(chunkCount: number): Promise<File> {
  const content = generateExactChunks(chunkCount)
  return new File([content], `large-${chunkCount}.txt`, { type: 'text/plain' })
}

/**
 * 创建测试文件
 */
export function createTestFile(filename: string, content: string): File {
  return new File([content], filename, { type: 'text/plain' })
}
```

---

## Coverage Validation

### Expected Coverage by File

| 文件 | 新增代码行 | 测试覆盖目标 | 关键分支 |
|------|-----------|-------------|---------|
| `chunkingService.ts` | ~30 行 | 100% | 空内容检查, 截断逻辑 |
| `embeddingService.ts` | ~15 行 | 100% | 维度验证循环 |
| 错误类型定义 | ~5 行 | 100% | 新增错误类型 |

### Coverage Gaps Check

运行覆盖率报告后检查:

```bash
npm run test:coverage

# 检查关键文件
open coverage/lcov-report/chunkingService.ts.html
open coverage/lcov-report/embeddingService.ts.html
```

**必须达到**:
- 语句覆盖率 (Statements): 100%
- 分支覆盖率 (Branches): 100%
- 函数覆盖率 (Functions): 100%
- 行覆盖率 (Lines): 100%

---

## Quality Checklist

验证测试设计质量：

- [x] **Every AC has test coverage**: 所有 7 个 AC 都有对应测试
- [x] **Test levels are appropriate**: 
  - 单元测试用于纯逻辑验证 (空文档、维度、截断逻辑)
  - 集成测试用于端到端流程和数据库验证
  - 无不必要的 E2E 测试
- [x] **No duplicate coverage**: 每个场景只在一个层级测试
- [x] **Priorities align with risk**: 
  - 高风险 PERF-001, DATA-001 → P0
  - 中风险 OPS-001 → P1
  - 低风险 TECH-001 → P1
- [x] **Test IDs follow naming convention**: 4.5-{LEVEL}-{SEQ}
- [x] **Scenarios are atomic**: 每个测试验证一个明确的行为
- [x] **Risk coverage complete**: 所有 6 个风险都有缓解测试

---

## Success Criteria

**测试设计成功标准**:

1. ✅ **完整性**: 所有 AC 和风险都有测试覆盖
2. ✅ **效率性**: Shift-left 策略，61% 单元测试
3. ✅ **可维护性**: 清晰的测试结构和命名
4. ✅ **可追溯性**: 每个测试场景映射到 AC 和风险
5. ✅ **可执行性**: 提供完整的实现指导

**执行后验收**:
- 所有 23 个测试用例通过
- 代码覆盖率 100%
- 所有风险得到缓解
- 测试执行时间 < 15 分钟

---

## Conclusion

**测试策略总结**:
- ✅ **23 个测试场景** 全面覆盖 7 个验收标准
- ✅ **100% 风险覆盖** - 所有识别的风险都有对应测试
- ✅ **Shift-left approach** - 61% 单元测试提供快速反馈
- ✅ **优先级清晰** - 70% P0 测试确保关键路径
- ✅ **可执行性强** - 提供完整的实现代码示例

**推荐执行顺序**:
1. Phase 1: P0 单元测试 (14 个) - 5 分钟
2. Phase 2: P0 集成测试 (7 个) - 3 分钟
3. Phase 3: P1 测试 (6 个) - 4 分钟
4. Phase 4: P2 边界测试 (2 个) - 1 分钟

**总执行时间**: ~13 分钟

---

**报告生成时间**: 2025-01-14  
**设计者**: Quinn (测试架构师)  
**下次审查**: 实施后验证覆盖率


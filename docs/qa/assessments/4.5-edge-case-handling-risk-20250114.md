# Risk Profile: Story 4.5

**Story**: 4.5 - 边界情况处理增强  
**Date**: 2025-01-14  
**Reviewer**: Quinn (测试架构师)

---

## Executive Summary

- **总识别风险数**: 6
- **关键风险 (Critical, score 9)**: 0
- **高风险 (High, score 6)**: 1
- **中等风险 (Medium, score 4)**: 3
- **低风险 (Low, score 2-3)**: 2
- **总体风险分数**: 71/100

**风险评级**: 🟡 **MEDIUM** - 需要关注但可控

**关键发现**:
- 最高风险为 PERF-001（超大文档处理），分数 6，需要优先缓解
- 没有关键级别风险（score 9）
- 主要风险集中在数据完整性和性能方面
- Unicode 处理风险较低，因为 LangChain 已有良好支持

---

## Critical Risks Requiring Immediate Attention

### ✅ 无关键风险 (Score 9)

此 Story 没有识别出关键级别的风险。

---

## High Risks Requiring Priority Mitigation

### 1. PERF-001: 超大文档未截断导致资源耗尽

**分数**: 6 (High)  
**概率**: Medium (2) - 用户可能上传技术手册、论文集等大型文档  
**影响**: High (3) - 可能导致：
- 向量数据库存储压力过大
- 批量嵌入生成超时
- 内存溢出
- API 配额快速耗尽

**受影响组件**:
- `chunkingService.ts` (分块逻辑)
- `embeddingService.ts` (批量处理)
- Supabase pgvector 存储

**缓解策略**:
- ✅ **Preventive（预防性）**:
  1. 实现 `MAX_CHUNKS = 10000` 硬限制
  2. 在分块后立即检查数量
  3. 截断前记录完整的原始 chunks 数量
  4. 在文档 metadata 中标记截断状态
  
- ✅ **Detective（检测性）**:
  1. 记录 WARN 级别日志，包含 documentId、originalCount、截断信息
  2. 监控超过 8000 chunks 的文档（接近阈值告警）
  
- ✅ **Corrective（修正性）**:
  1. 前端显示"文档已截断"提示
  2. 提供"重新上传较小片段"建议

**测试要求**:
- 单元测试: 恰好 10000 chunks（边界）
- 单元测试: 15000 chunks（超限截断）
- 集成测试: 端到端超大文档上传
- 性能测试: 10000 chunks 处理时间应 < 5 分钟

**剩余风险**: Low - 截断后的文档仍然包含前 10000 chunks 的有效内容

**责任人**: Dev (James)  
**时间线**: 在部署前完成

---

## Medium Risks Requiring Attention

### 2. DATA-001: 空文档检测不完整

**分数**: 4 (Medium)  
**概率**: Medium (2) - 用户可能误上传空文件或损坏的文件  
**影响**: Medium (2) - 导致数据库存储无意义记录，增加存储成本

**受影响组件**:
- `chunkingService.ts` (parseDocument 输出)
- `documents` 表

**缓解策略**:
1. 增强空内容检测: `if (!parsedContent || parsedContent.trim().length === 0)`
2. 抛出友好错误: "文档内容为空，无法处理"
3. 设置文档状态为 FAILED
4. 在 metadata 中记录错误类型: `EMPTY_CONTENT`

**测试要求**:
- 单元测试: 完全空文档
- 单元测试: 仅包含空白字符的文档
- 集成测试: 端到端上传空文件验证错误消息

**剩余风险**: Minimal - 检测后直接拒绝处理

---

### 3. OPS-001: 错误日志不结构化

**分数**: 4 (Medium)  
**概率**: Medium (2) - 当前日志格式不统一  
**影响**: Medium (2) - 生产环境问题排查困难，无法快速定位根因

**受影响组件**:
- `chunkingService.ts` catch blocks
- `embeddingService.ts` catch blocks
- 所有服务的错误处理

**缓解策略**:
1. 标准化错误日志格式:
   ```typescript
   console.error('[Service] 错误:', {
     timestamp: new Date().toISOString(),
     documentId,
     errorType,
     message,
     context: { /* 相关参数 */ }
   })
   ```
2. 定义统一的 `errorType` 枚举
3. 在所有 catch block 中应用结构化日志

**测试要求**:
- 单元测试: 验证日志格式包含所有必需字段
- 集成测试: 触发错误并检查日志输出

**剩余风险**: Low - 实施后日志可直接导入监控系统

---

### 4. DATA-003: 文档截断后用户不知情

**分数**: 4 (Medium)  
**概率**: Medium (2) - 用户可能不察觉截断  
**影响**: Medium (2) - 用户期望查询完整文档，但实际只有部分内容

**受影响组件**:
- 前端文档列表 UI
- 文档详情页

**缓解策略**:
1. 在 `documents` 表 metadata 中记录:
   ```json
   {
     "chunking": {
       "truncated": true,
       "originalChunksCount": 15000,
       "storedChunksCount": 10000
     }
   }
   ```
2. 前端显示截断标识 (🔸图标 + Tooltip)
3. 文档详情页显示: "此文档已被截断至前 10000 个片段"

**测试要求**:
- 集成测试: 验证 metadata 正确保存
- UI 测试: 验证截断标识显示

**剩余风险**: Low - 透明提示后用户可自行决定是否重新上传

---

## Low Risks Requiring Monitoring

### 5. DATA-002: 向量维度不匹配

**分数**: 3 (Low)  
**概率**: Low (1) - 配置稳定后很少发生  
**影响**: High (3) - 一旦发生会导致所有检索失败

**受影响组件**:
- `embeddingService.ts` (向量生成)
- Supabase pgvector 表

**缓解策略**:
1. 在每个向量生成后验证维度:
   ```typescript
   const expectedDimension = llmConfig.provider === 'zhipu' ? 1024 : 1536
   if (vector.length !== expectedDimension) {
     throw new EmbeddingError(
       `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.length}`,
       'DIMENSION_MISMATCH'
     )
   }
   ```
2. 记录 ERROR 级别日志，包含 provider 和实际维度
3. 阻止不匹配的向量写入数据库

**测试要求**:
- 单元测试: 模拟维度不匹配场景
- 单元测试: 验证 ZhipuAI (1024) 和 OpenAI (1536) 维度

**剩余风险**: Minimal - 验证后会立即失败，不会污染数据库

---

### 6. TECH-001: Unicode 特殊字符处理错误

**分数**: 2 (Low)  
**概率**: Low (1) - LangChain RecursiveCharacterTextSplitter 已支持 Unicode  
**影响**: Medium (2) - 中文文档分块错误会导致检索不准确

**受影响组件**:
- `chunkingService.ts` (RecursiveCharacterTextSplitter)

**缓解策略**:
1. 依赖 LangChain 的内置 Unicode 支持
2. 通过集成测试验证:
   - 纯中文文档
   - 包含 Emoji 的文档
   - 混合中英文文档
   - 特殊符号文档
3. 如发现问题，可配置自定义分隔符

**测试要求**:
- 集成测试: 5 个 Unicode 场景（详见 Story AC5）
- 手动验证: 上传中文技术文档验证检索准确性

**剩余风险**: Minimal - LangChain 已验证支持

---

## Risk Distribution

### By Category

| 类别 | 风险数量 | 关键/高风险 | 中等风险 | 低风险 |
|------|----------|-------------|----------|--------|
| 数据风险 (DATA) | 3 | 0 | 2 | 1 |
| 性能风险 (PERF) | 1 | 1 | 0 | 0 |
| 运维风险 (OPS) | 1 | 0 | 1 | 0 |
| 技术风险 (TECH) | 1 | 0 | 0 | 1 |
| **总计** | **6** | **1** | **3** | **2** |

### By Component

| 组件 | 风险数量 | 最高风险分数 |
|------|----------|--------------|
| chunkingService.ts | 4 | 6 (PERF-001) |
| embeddingService.ts | 2 | 4 (OPS-001) |
| 前端 UI | 1 | 4 (DATA-003) |
| 数据库 | 2 | 3 (DATA-002) |

**关键观察**:
- `chunkingService.ts` 是最高风险组件，承载 4 个风险
- 大部分风险可通过单元测试验证缓解效果

---

## Detailed Risk Register

| 风险 ID | 类别 | 标题 | 概率 | 影响 | 分数 | 优先级 | 缓解策略 | 剩余风险 |
|---------|------|------|------|------|------|--------|----------|----------|
| PERF-001 | 性能 | 超大文档未截断 | Medium (2) | High (3) | 6 | High | 实施 MAX_CHUNKS 硬限制 | Low |
| DATA-001 | 数据 | 空文档检测不完整 | Medium (2) | Medium (2) | 4 | Medium | 增强 trim() 检查 | Minimal |
| OPS-001 | 运维 | 错误日志不结构化 | Medium (2) | Medium (2) | 4 | Medium | 标准化日志格式 | Low |
| DATA-003 | 数据 | 截断后用户不知情 | Medium (2) | Medium (2) | 4 | Medium | UI 显示截断标识 | Low |
| DATA-002 | 数据 | 维度不匹配 | Low (1) | High (3) | 3 | Low | 每个向量验证维度 | Minimal |
| TECH-001 | 技术 | Unicode 处理错误 | Low (1) | Medium (2) | 2 | Low | 集成测试验证 | Minimal |

---

## Risk-Based Testing Strategy

### Priority 1: High Risk Tests (PERF-001)

**必须测试的场景**:

1. **超大文档截断** (单元测试):
   - 输入: 15000 chunks
   - 预期: 截断到 10000，记录 WARN 日志，metadata 包含 truncated 标记
   
2. **边界测试** (单元测试):
   - 输入: 恰好 10000 chunks
   - 预期: 不截断，无告警
   
3. **性能测试** (集成测试):
   - 输入: 10000 chunks 的大型 PDF
   - 预期: 处理时间 < 5 分钟，无内存溢出

4. **存储压力测试** (性能测试):
   - 场景: 连续上传 5 个 10000 chunks 的文档
   - 预期: pgvector 存储正常，无超时

**测试数据要求**:
- 生成工具: 使用 `scripts/generate-test-fixtures.ts` 生成大型测试文件
- 文件大小: 50MB PDF (预计产生 12000+ chunks)

---

### Priority 2: Medium Risk Tests (DATA-001, OPS-001, DATA-003)

**空文档检测**:
- 完全空文档 (`''`)
- 仅空格 (`'   '`)
- 仅换行符 (`'\n\n\n'`)
- 混合空白字符 (`' \n\t '`)

**错误日志验证**:
- 触发 ChunkingError，检查日志包含 timestamp, documentId, errorType
- 触发 EmbeddingError，检查日志格式一致

**截断提示验证**:
- 集成测试: 上传超大文档后查询 metadata
- UI 测试: 验证前端显示 "🔸已截断" 标识

---

### Priority 3: Low Risk Tests (DATA-002, TECH-001)

**维度验证** (单元测试):
- Mock ZhipuAI 返回 1024 维向量 → 通过
- Mock ZhipuAI 返回 1536 维向量 → 抛出 DIMENSION_MISMATCH
- Mock OpenAI 返回 1536 维向量 → 通过
- Mock OpenAI 返回 1024 维向量 → 抛出 DIMENSION_MISMATCH

**Unicode 处理** (集成测试):
- 纯中文文档: `测试文档.pdf`
- Emoji 文档: `Hello 👋 World 🚀.txt`
- 混合特殊符号: `Price €100 ©2025.txt`

---

## Risk Acceptance Criteria

### Must Fix Before Production ⚠️

1. **PERF-001** (超大文档截断):
   - ✅ 必须实施 `MAX_CHUNKS` 限制
   - ✅ 必须记录完整的截断日志
   - ✅ 必须通过性能测试

2. **DATA-001** (空文档检测):
   - ✅ 必须增强 trim() 检查
   - ✅ 必须设置 FAILED 状态

### Can Deploy with Mitigation 🟡

3. **OPS-001** (结构化日志):
   - ✅ 可以在后续迭代中完善
   - ⚠️ 建议本次部署前实施，提升可观测性

4. **DATA-003** (截断提示):
   - ✅ 可以先部署后端逻辑
   - ⚠️ 前端 UI 可在下个 Sprint 优化

### Accepted Risks ✅

5. **DATA-002** (维度不匹配):
   - 风险接受理由: 配置稳定后几乎不会发生
   - 缓解措施: 验证逻辑到位，一旦发生会立即失败
   
6. **TECH-001** (Unicode 处理):
   - 风险接受理由: LangChain 已验证支持
   - 缓解措施: 集成测试覆盖主要场景

---

## Monitoring Requirements

### Post-deployment Monitoring

**性能指标** (PERF-001):
- 监控指标: `document_chunks_count`
- 告警阈值: chunks > 8000 时发送通知
- 仪表盘: 显示文档大小分布直方图

**错误率** (OPS-001):
- 监控日志: 所有 `console.error` 输出
- 告警条件: ERROR 数量 > 5/小时
- 分类统计: 按 errorType 分组展示

**数据完整性** (DATA-003):
- 监控指标: 截断文档数量占比
- 统计周期: 每日汇总
- 报告内容: 如果截断率 > 5%，建议调整文档上传指南

---

## Risk Review Triggers

**需要重新评估风险的触发条件**:

1. **架构变更**:
   - 更换 LLM Provider (例如从 ZhipuAI 切到 OpenAI)
   - 更改 chunk size 或 overlap 参数
   - 迁移到不同的向量数据库

2. **性能问题报告**:
   - 用户报告上传超时
   - pgvector 存储空间告警
   - 批量 embedding 生成失败

3. **数据不一致**:
   - 检索结果不完整
   - 向量维度错误告警
   - 文档状态异常

4. **新功能需求**:
   - 支持更大文档（> 10000 chunks）
   - 新增文档类型支持
   - 新的 Unicode 字符集支持

---

## Recommendations Summary

### Immediate Actions (Before Deployment)

1. ✅ **实施 PERF-001 缓解措施** (高优先级):
   - 添加 `MAX_CHUNKS = 10000` 常量
   - 实现截断逻辑和日志记录
   - 更新 metadata 结构
   - 编写单元测试和性能测试

2. ✅ **实施 DATA-001 缓解措施** (中优先级):
   - 增强空文档检测逻辑
   - 添加友好错误消息
   - 编写单元测试

3. ⚠️ **建议实施 OPS-001** (中优先级):
   - 标准化错误日志格式
   - 定义 errorType 枚举
   - 在所有服务中统一应用

### Future Improvements

4. 🔄 **DATA-003 前端增强** (可后续迭代):
   - 在文档列表显示截断标识
   - 提供详细的截断信息 Tooltip
   - 建议用户分段上传

5. 📊 **监控和告警设置**:
   - 配置 chunks 数量告警
   - 设置错误率监控
   - 创建数据完整性仪表盘

---

## Conclusion

**总体风险评估**: 🟡 **MEDIUM (可控)**

**关键发现**:
- ✅ 无关键级别风险 (score 9)
- ⚠️ 1 个高风险 (PERF-001) 需要优先缓解
- 🔄 3 个中等风险可通过测试和监控控制
- ✅ 2 个低风险风险接受

**推荐行动**:
1. **部署前必须完成**: PERF-001, DATA-001 缓解措施
2. **强烈建议完成**: OPS-001 结构化日志
3. **可后续迭代**: DATA-003 前端 UI 增强

**质量门控建议**: 
- 如果 PERF-001 和 DATA-001 的单元测试全部通过 → **Gate: PASS**
- 如果缺少性能测试 → **Gate: CONCERNS**
- 如果未实施截断逻辑 → **Gate: FAIL**

---

**报告生成时间**: 2025-01-14  
**下次审查建议**: 实施后或检测到性能问题时  
**责任人**: Dev (James) 实施, QA (Quinn) 验证


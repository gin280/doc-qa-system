# Story 3.2 人工质量评估协议

**Story**: 3.2 - RAG向量检索实现  
**AC Reference**: AC9 - 检索质量验证  
**目标**: Top-5准确率 >= 85%  
**评估日期**: _待执行_  
**评估人员**: _待指定_

---

## 评估目标

验证RAG向量检索系统的检索准确性，确保返回的Top-5结果与用户问题相关，满足产品质量要求。

**成功标准**: Top-5准确率 >= 85%

---

## 测试数据准备

### 测试文档清单

准备以下3类文档用于评估：

| 文档ID | 文档类型 | 文件 | 大小 | 页数 | 主题 |
|--------|---------|------|------|------|------|
| DOC-1  | 技术文档 | React Official Guide | ~2MB | ~50页 | React Hooks, 组件, 状态管理 |
| DOC-2  | 业务文档 | Product Requirements | ~500KB | ~30页 | 产品功能, 用户需求, 业务流程 |
| DOC-3  | 学术文档 | ML Research Paper | ~1MB | ~20页 | 机器学习, 算法, 实验方法 |

### 测试问题集 (20个问题)

#### 技术文档问题 (DOC-1: React Guide) - 7个问题

| # | 类型 | 问题 | 预期答案关键词 |
|---|------|------|---------------|
| Q1 | 事实性 | What is React Hooks? | hooks, function components, state, lifecycle |
| Q2 | 操作性 | How to use useState to manage state? | useState, initial state, setter function |
| Q3 | 比较性 | What's the difference between useEffect and useLayoutEffect? | timing, paint, synchronous, asynchronous |
| Q4 | 解释性 | Why do we need useCallback for performance? | memoization, re-render, dependency |
| Q5 | 事实性 | What are the new features in React 18? | concurrent rendering, automatic batching |
| Q6 | 操作性 | How to avoid infinite loops in useEffect? | dependency array, conditions |
| Q7 | 操作性 | What are the best practices for custom Hooks? | naming convention, reusability |

#### 业务文档问题 (DOC-2: Product Requirements) - 7个问题

| # | 类型 | 问题 | 预期答案关键词 |
|---|------|------|---------------|
| Q8 | 事实性 | 产品的核心功能是什么？ | 文档问答, 智能检索, AI对话 |
| Q9 | 操作性 | 如何创建新用户账户？ | 注册, 邮箱验证, OAuth登录 |
| Q10 | 比较性 | 免费版和付费版有什么区别？ | 文档数量, 查询次数, 高级功能 |
| Q11 | 解释性 | 为什么要实现这个功能？ | 用户痛点, 价值主张, 竞争优势 |
| Q12 | 事实性 | 产品的目标用户是谁？ | 知识工作者, 研究人员, 学生 |
| Q13 | 操作性 | 文档上传的大小限制是多少？ | 最大10MB, 支持格式 |
| Q14 | 事实性 | 系统的技术栈是什么？ | Next.js, TypeScript, PostgreSQL |

#### 学术文档问题 (DOC-3: ML Paper) - 6个问题

| # | 类型 | 问题 | 预期答案关键词 |
|---|------|------|---------------|
| Q15 | 事实性 | What is the main hypothesis of this research? | hypothesis, assumption, research question |
| Q16 | 操作性 | How was the experiment designed? | methodology, dataset, procedure |
| Q17 | 比较性 | How does this differ from previous research? | novelty, contribution, comparison |
| Q18 | 解释性 | Why was this research method chosen? | justification, advantages, suitability |
| Q19 | 事实性 | What were the main findings? | results, conclusions, significance |
| Q20 | 事实性 | What are the limitations of this study? | limitations, future work, constraints |

---

## 评估方法

### 相关性评分标准

对每个问题的Top-5检索结果进行评分：

| 评分 | 标签 | 说明 | 示例 |
|------|------|------|------|
| 2 | ✅ 相关 | chunk内容直接回答问题或提供关键信息 | 问题是"What is useState?"，chunk详细解释了useState的用法 |
| 1 | ⚠️ 部分相关 | chunk包含相关关键词但信息不完整或不够精确 | 问题是"What is useState?"，chunk仅提到useState但未解释 |
| 0 | ❌ 不相关 | chunk与问题无关或信息完全不匹配 | 问题是"What is useState?"，chunk讲的是CSS样式 |

### 计算方法

**单个问题的准确率**:
```
问题准确率 = (相关结果数 × 2 + 部分相关结果数 × 1) / 10
```

**整体准确率**:
```
总准确率 = Σ(每个问题的准确率) / 问题总数
```

**目标**: 总准确率 >= 85%

---

## 评估表格

### 评估记录模板

| 问题ID | 问题 | Chunk1 | Chunk2 | Chunk3 | Chunk4 | Chunk5 | 得分 | 准确率 |
|-------|------|--------|--------|--------|--------|--------|------|-------|
| Q1 | What is React Hooks? | ✅(2) | ✅(2) | ⚠️(1) | ⚠️(1) | ❌(0) | 6 | 60% |
| Q2 | ... | | | | | | | |
| ... | | | | | | | | |
| **总计** | | | | | | | **XXX** | **XX%** |

### 详细记录格式

对于每个问题，记录：

```markdown
#### Q1: What is React Hooks?

**文档**: DOC-1 (React Guide)  
**查询时间**: 2025-01-XX XX:XX:XX  
**检索用时**: XXXms  
**总匹配数**: X

**Top-5结果评分**:

1. **Chunk ID**: chunk-123  
   **Score**: 0.89  
   **Content Preview**: "React Hooks are functions that let you use state..."  
   **评分**: ✅ 相关 (2分)  
   **理由**: 直接解释了Hooks的定义和用途

2. **Chunk ID**: chunk-456  
   **Score**: 0.85  
   **Content Preview**: "useState is a Hook that lets you add state..."  
   **评分**: ✅ 相关 (2分)  
   **理由**: 提供了具体Hook的示例

3. **Chunk ID**: chunk-789  
   **Score**: 0.78  
   **Content Preview**: "Hooks allow you to reuse stateful logic..."  
   **评分**: ⚠️ 部分相关 (1分)  
   **理由**: 提到了Hooks但缺少完整定义

4. **Chunk ID**: chunk-012  
   **Score**: 0.72  
   **Content Preview**: "Component lifecycle in React..."  
   **评分**: ⚠️ 部分相关 (1分)  
   **理由**: 相关但未直接回答问题

5. **Chunk ID**: chunk-345  
   **Score**: 0.68  
   **Content Preview**: "React components can be function or class..."  
   **评分**: ❌ 不相关 (0分)  
   **理由**: 讨论组件类型，与Hooks无关

**问题准确率**: (2+2+1+1+0) / 10 = **60%**
```

---

## 执行步骤

### 准备阶段

1. **环境准备** (15分钟)
   - [ ] 确认测试环境可访问
   - [ ] 上传3个测试文档到系统
   - [ ] 等待文档向量化完成（状态变为READY）
   - [ ] 验证文档可正常检索

2. **文档准备** (15分钟)
   - [ ] 创建评估记录Excel/Google Sheet
   - [ ] 准备20个测试问题的列表
   - [ ] 设置录屏工具（可选，用于复盘）

### 执行阶段

3. **逐个问题评估** (2-3小时)
   
   对每个问题：
   1. 在系统中输入问题
   2. 记录检索用时和返回结果数
   3. 查看Top-5结果的内容预览
   4. 对每个chunk评分（2/1/0）
   5. 记录评分理由
   6. 计算该问题的准确率

4. **特殊情况处理**
   - 如果返回结果 < 5个，按实际数量评分
   - 如果系统返回错误，记录错误信息并标记为失败
   - 如果查询超时（> 3秒），记录超时情况

### 分析阶段

5. **结果汇总** (30分钟)
   - [ ] 计算总体准确率
   - [ ] 分析不同文档类型的准确率差异
   - [ ] 分析不同问题类型的准确率差异
   - [ ] 识别常见的检索失败模式

6. **问题分析** (30分钟)
   
   如果准确率 < 85%，分析原因：
   - [ ] 分块策略不当（chunk太大/太小）？
   - [ ] 相似度阈值不合理（minScore=0.3太宽松/严格）？
   - [ ] Top-K数量不够（默认5个不足）？
   - [ ] Embedding模型不适合该领域？
   - [ ] 文档质量问题（内容不清晰）？

---

## 评估报告模板

### 执行摘要

- **评估日期**: YYYY-MM-DD
- **评估人员**: 姓名
- **评估环境**: 测试环境 / 生产环境
- **评估文档数**: 3个
- **评估问题数**: 20个
- **总准确率**: XX.X%
- **是否达标**: ✅ 达标 / ❌ 未达标 (目标 >= 85%)

### 分类统计

#### 按文档类型

| 文档类型 | 问题数 | 总得分 | 准确率 | 评价 |
|---------|--------|--------|--------|------|
| 技术文档 | 7 | XX | XX% | 优秀/良好/需改进 |
| 业务文档 | 7 | XX | XX% | 优秀/良好/需改进 |
| 学术文档 | 6 | XX | XX% | 优秀/良好/需改进 |

#### 按问题类型

| 问题类型 | 问题数 | 总得分 | 准确率 | 评价 |
|---------|--------|--------|--------|------|
| 事实性 | 8 | XX | XX% | |
| 操作性 | 7 | XX | XX% | |
| 比较性 | 3 | XX | XX% | |
| 解释性 | 2 | XX | XX% | |

### 性能指标

- **平均检索用时**: XXXms
- **P95检索用时**: XXXms
- **检索成功率**: XX%（成功返回结果的比例）
- **平均返回chunks数**: X.X个

### 关键发现

#### 优点

1. ✅ [发现1，如：事实性问题检索准确率高]
2. ✅ [发现2，如：技术文档检索效果良好]
3. ✅ [发现3]

#### 问题

1. ❌ [问题1，如：比较性问题准确率低]
2. ❌ [问题2，如：学术文档检索效果差]
3. ⚠️ [问题3，如：检索用时偶尔超过500ms]

#### 具体案例

**最佳案例** (准确率 >= 90%):
- Q1: What is React Hooks? - 准确率 90%
- 原因分析: 文档中有完整清晰的定义段落

**最差案例** (准确率 < 60%):
- Q17: How does this differ from previous research? - 准确率 40%
- 原因分析: 学术论文的比较性内容分散，难以精准定位

### 改进建议

#### 立即改进 (P0)

1. **调整相似度阈值**
   - 当前: minScore = 0.3
   - 建议: 提高到 0.5
   - 理由: 降低不相关结果比例

2. **优化分块策略**
   - 当前: 1000 tokens/chunk
   - 建议: 调整为 800 tokens
   - 理由: 提高内容语义完整性

#### 中期改进 (P1)

1. 为不同文档类型使用不同检索参数
2. 实现混合检索（向量 + BM25）
3. 添加结果重排序逻辑

#### 长期优化 (P2)

1. 微调Embedding模型
2. 用户反馈收集和持续优化
3. A/B测试不同检索策略

### 结论

[根据实际结果填写结论，如：]

总体准确率为 XX%，[达标/未达标]。技术文档和业务文档的检索效果良好，但学术文档需要优化。建议[具体建议]后重新评估。

---

**评估人签名**: _______________  
**审核人签名**: _______________  
**日期**: YYYY-MM-DD

---

## 附录：测试文档准备指南

### 推荐测试文档

1. **技术文档**: React官方文档 (https://react.dev/learn)
   - 下载为PDF或使用现有文档
   - 确保包含Hooks、组件、状态管理等核心主题

2. **业务文档**: 项目自身的PRD文档
   - 使用 docs/prd.md 或类似文档
   - 确保包含功能描述、用户需求、业务流程

3. **学术文档**: 任一ML/AI研究论文
   - 推荐: arXiv上的经典论文
   - 确保有完整的Abstract、Methodology、Results部分

### 文档质量检查清单

上传前确认：
- [ ] 文档大小在系统限制内（< 10MB）
- [ ] 文档格式支持（PDF/DOCX/TXT）
- [ ] 文档内容清晰可读（无OCR错误）
- [ ] 文档主题与测试问题匹配
- [ ] 文档长度适中（不要太短 < 5页）

---

**文档版本**: 1.0  
**创建日期**: 2025-01-08  
**最后更新**: 2025-01-08  
**文档所有者**: QA Team

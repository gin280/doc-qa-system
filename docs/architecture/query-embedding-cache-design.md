# Query Embedding ç¼“å­˜æ¶æ„è®¾è®¡

**æ¶æ„å¸ˆ**: Winston  
**åˆ›å»ºæ—¥æœŸ**: 2025-01-10  
**Story**: 4.2 - Query Embedding ç¼“å­˜  
**çŠ¶æ€**: Design Complete â†’ Ready for Implementation

---

## ğŸ“‹ è®¾è®¡ç›®æ ‡

### æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | æå‡ |
|-----|------|------|------|
| æŸ¥è¯¢å‘é‡åŒ–æ—¶é—´ | 380ms | ~5ms (ç¼“å­˜å‘½ä¸­) | 98.7% â¬‡ï¸ |
| æ€»æ£€ç´¢æ—¶é—´ | 620ms | 245ms (ç¼“å­˜å‘½ä¸­) | 60.5% â¬‡ï¸ |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | >60% | - |

### æ¶æ„åŸåˆ™

1. **é€æ˜æ€§**: å¯¹è°ƒç”¨æ–¹é€æ˜ï¼Œæ— éœ€ä¿®æ”¹ RetrievalService
2. **å¯é æ€§**: ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
3. **å¯è§‚æµ‹æ€§**: å®Œæ•´çš„ç›‘æ§æŒ‡æ ‡å’Œæ—¥å¿—
4. **å¯æ‰©å±•æ€§**: æ”¯æŒæœªæ¥å¤š LLM æä¾›å•†
5. **æˆæœ¬æ•ˆç›Š**: ä½¿ç”¨ç°æœ‰ Upstash Redis åŸºç¡€è®¾æ–½

---

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

### å½“å‰æ¶æ„ (æ— ç¼“å­˜)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·æŸ¥è¯¢   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  queryVectorizer.vectorize()â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ~380ms
â”‚   LLM API (Embedding)       â”‚ â—„â”€â”€â”€â”€â”€â”€â”€ æ¯æ¬¡è°ƒç”¨
â”‚   (æ™ºè°±AI embedding-2)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     å‘é‡æ£€ç´¢ (pgvector)     â”‚  ~240ms
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      è¿”å›ç»“æœ (620ms)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç›®æ ‡æ¶æ„ (Query Embedding ç¼“å­˜)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·æŸ¥è¯¢   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  queryVectorizer.vectorize() - å¢å¼ºç‰ˆ        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â–º 1. è®¡ç®—ç¼“å­˜é”®: qv:{hash(query)}
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Redis ç¼“å­˜æŸ¥è¯¢                         â”‚
â”‚       TTL: 1å°æ—¶                             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ å‘½ä¸­ â”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ~5ms
       â”‚           â”‚ è¿”å›ç¼“å­˜å‘é‡  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€ 60%+ å‘½ä¸­ç‡
       â”‚           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â”œâ”€ æœªå‘½ä¸­ â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ~380ms
       â”‚            â”‚  LLM API (Embedding) â”‚ â—„â”€â”€â”€â”€â”€â”€â”€ 40%- æœªå‘½ä¸­
       â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â”‚                   â”œâ”€ å­˜å…¥ç¼“å­˜ (å¼‚æ­¥)
       â”‚                   â”‚
       â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å‘é‡æ£€ç´¢ (pgvector)              â”‚  ~240ms
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¿”å›ç»“æœ                                    â”‚
â”‚  ç¼“å­˜å‘½ä¸­: 245ms (60%+ åœºæ™¯)                â”‚
â”‚  ç¼“å­˜æœªå‘½ä¸­: 620ms (40%- åœºæ™¯)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ ç¼“å­˜é”®è®¾è®¡

### å‘½åç©ºé—´ç­–ç•¥

é‡‡ç”¨å±‚æ¬¡åŒ–å‘½åç©ºé—´ï¼Œä¸ç°æœ‰ `rag:query:*` åŒºåˆ†ï¼š

```
qv:{provider}:{hash}
```

**ç¤ºä¾‹**:
```
qv:zhipu:a3f8b9c2d1e4f5a6b7c8d9e0f1a2b3c4
qv:openai:d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9
```

### é”®è®¾è®¡ç†ç”±

1. **qv** (Query Vector): æ˜ç¡®æ ‡è¯†ä¸ºæŸ¥è¯¢å‘é‡ç¼“å­˜
2. **{provider}**: LLM æä¾›å•† (zhipu/openai/...)
   - ä¸åŒæä¾›å•†çš„å‘é‡ç»´åº¦ä¸åŒ (æ™ºè°±1024 vs OpenAI1536)
   - æ”¯æŒæœªæ¥å¤š LLM åˆ‡æ¢
3. **{hash}**: MD5(normalized_query)
   - å½’ä¸€åŒ–: `query.trim().toLowerCase()`
   - 32å­—èŠ‚ MD5: èŠ‚çœ Redis å†…å­˜

### Hash å‡½æ•°è®¾è®¡

```typescript
import { createHash } from 'crypto'

function generateEmbeddingCacheKey(
  query: string, 
  provider: string = 'zhipu'
): string {
  // 1. å½’ä¸€åŒ–æŸ¥è¯¢
  const normalized = query
    .trim()
    .toLowerCase()
    .replace(/\s+/g, ' ')  // å¤šç©ºæ ¼å½’ä¸€
  
  // 2. è®¡ç®— MD5 hash
  const hash = createHash('md5')
    .update(normalized, 'utf8')
    .digest('hex')
  
  // 3. ç”Ÿæˆç¼“å­˜é”®
  return `qv:${provider}:${hash}`
}

// ç¤ºä¾‹
generateEmbeddingCacheKey('ä»€ä¹ˆæ˜¯AI?', 'zhipu')
// â†’ 'qv:zhipu:a3f8b9c2d1e4f5a6b7c8d9e0f1a2b3c4'

generateEmbeddingCacheKey('ä»€ä¹ˆæ˜¯AIï¼Ÿ', 'zhipu')  // ä¸­æ–‡æ ‡ç‚¹
// â†’ 'qv:zhipu:a3f8b9c2d1e4f5a6b7c8d9e0f1a2b3c4'  // ç›¸åŒ hash
```

---

## ğŸ’¾ ç¼“å­˜ç­–ç•¥è®¾è®¡

### TTL (Time-To-Live) ç­–ç•¥

**æ¨è TTL: 1 å°æ—¶ (3600ç§’)**

**ç†ç”±**:
1. **ç›¸ä¼¼é—®é¢˜é¢‘ç‡**: ç”¨æˆ·åœ¨çŸ­æ—¶é—´å†…é‡å¤æˆ–ç±»ä¼¼æŸ¥è¯¢
2. **LLM ç¨³å®šæ€§**: embedding-2 æ¨¡å‹è¾“å‡ºç¨³å®šï¼Œå‘é‡ä¸ä¼šå˜åŒ–
3. **å†…å­˜æ•ˆç‡**: 1å°æ—¶è¶³å¤Ÿè¦†ç›–ç”¨æˆ·ä¼šè¯ï¼Œé¿å…æ— é™å¢é•¿
4. **å¹³è¡¡**: è¶³å¤Ÿé•¿ä»¥æé«˜å‘½ä¸­ç‡ï¼Œè¶³å¤ŸçŸ­ä»¥é‡Šæ”¾å†·æ•°æ®

**TTL å¯¹æ¯”åˆ†æ**:

| TTL | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåº¦ |
|-----|------|------|--------|
| 5åˆ†é’Ÿ | å¿«é€Ÿé‡Šæ”¾å†…å­˜ | å‘½ä¸­ç‡ä½ï¼Œæ”¶ç›Šæœ‰é™ | âŒ |
| 30åˆ†é’Ÿ | è¦†ç›–çŸ­ä¼šè¯ | ç”¨æˆ·å¤šæ¬¡è®¿é—®é—´éš”å¯èƒ½è¶…è¿‡ | âš ï¸ |
| **1å°æ—¶** | **å¹³è¡¡å‘½ä¸­ç‡å’Œå†…å­˜** | **é€‚ä¸­** | âœ… æ¨è |
| 24å°æ—¶ | æé«˜å‘½ä¸­ç‡ | å†…å­˜å ç”¨å¤§ï¼Œå†·æ•°æ®å¤š | âš ï¸ |
| æ°¸ä¹… | æœ€é«˜å‘½ä¸­ç‡ | å†…å­˜æ— é™å¢é•¿ï¼Œéœ€è¦ä¸»åŠ¨æ¸…ç† | âŒ |

### é©±é€ç­–ç•¥

**Redis é…ç½®**: `maxmemory-policy = allkeys-lru`

**ç†ç”±**:
- LRU (Least Recently Used): è‡ªåŠ¨é©±é€æœ€å°‘ä½¿ç”¨çš„é”®
- ä¸ TTL é…åˆï¼Œè‡ªåŠ¨å†…å­˜ç®¡ç†
- Upstash Redis é»˜è®¤æ”¯æŒ

### ç¼“å­˜å¤§å°ä¼°ç®—

**å•ä¸ªå‘é‡å†…å­˜å ç”¨**:
```
Key: 'qv:zhipu:32å­—èŠ‚hash' = ~50 bytes
Value: 1024ç»´ float32 å‘é‡ = 1024 Ã— 4 = 4096 bytes
Metadata: ~100 bytes (Redis å†…éƒ¨)
Total: ~4250 bytes â‰ˆ 4.2 KB
```

**å®¹é‡è§„åˆ’**:

| ç¼“å­˜æ•°é‡ | å†…å­˜å ç”¨ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|
| 1,000 | ~4.2 MB | å°å‹åº”ç”¨ (100 DAU) |
| 10,000 | ~42 MB | ä¸­å‹åº”ç”¨ (1000 DAU) |
| 100,000 | ~420 MB | å¤§å‹åº”ç”¨ (10000 DAU) |

**Upstash Free Tier**: 10,000 commands/day, 256MB storage  
**é¢„æœŸ**: 10,000 ç¼“å­˜æ¡ç›® (~42MB) å®Œå…¨å¤Ÿç”¨

---

## ğŸ”„ ç¼“å­˜ä¸€è‡´æ€§ç­–ç•¥

### ä»€ä¹ˆæ—¶å€™å¤±æ•ˆç¼“å­˜?

#### åœºæ™¯ 1: LLM æä¾›å•†åˆ‡æ¢

**è§¦å‘æ¡ä»¶**: åˆ‡æ¢ LLM_PROVIDER ç¯å¢ƒå˜é‡

**ç­–ç•¥**: æ¸…é™¤æ‰€æœ‰ `qv:{old_provider}:*` é”®

```typescript
async function invalidateProviderCache(oldProvider: string): Promise<void> {
  const pattern = `qv:${oldProvider}:*`
  const keys = await redis.keys(pattern)
  if (keys.length > 0) {
    await redis.del(...keys)
    console.log(`[Cache] Invalidated ${keys.length} keys for provider ${oldProvider}`)
  }
}
```

#### åœºæ™¯ 2: Embedding æ¨¡å‹å‡çº§

**è§¦å‘æ¡ä»¶**: æ¨¡å‹ç‰ˆæœ¬å˜åŒ– (å¦‚ embedding-2 â†’ embedding-3)

**ç­–ç•¥**: 
1. **æ–¹æ¡ˆ A (æ¨è)**: ä¿®æ”¹ provider key (å¦‚ `zhipu-v2` â†’ `zhipu-v3`)
2. **æ–¹æ¡ˆ B**: æ¸…é™¤æ‰€æœ‰ç¼“å­˜ (ç®€å•ä½†å½±å“å‘½ä¸­ç‡)

```typescript
// æ–¹æ¡ˆ A: ç‰ˆæœ¬åŒ– provider
const PROVIDER_VERSION = 'zhipu-v2'  // é…ç½®åŒ–

function generateCacheKey(query: string): string {
  return `qv:${PROVIDER_VERSION}:${hash(query)}`
}
```

#### åœºæ™¯ 3: ä¸»åŠ¨åˆ·æ–° (ä¸éœ€è¦)

**ç»“è®º**: Query Embedding æ˜¯**å¹‚ç­‰æ“ä½œ**ï¼Œç›¸åŒæŸ¥è¯¢æ°¸è¿œè¿”å›ç›¸åŒå‘é‡ï¼Œæ— éœ€ä¸»åŠ¨åˆ·æ–°ã€‚

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡è®¾è®¡

### å…³é”®æŒ‡æ ‡

#### 1. ç¼“å­˜å‘½ä¸­ç‡

```typescript
class EmbeddingCacheMetrics {
  private hits = 0
  private misses = 0
  
  get hitRate(): number {
    const total = this.hits + this.misses
    return total === 0 ? 0 : this.hits / total
  }
  
  recordHit(): void {
    this.hits++
  }
  
  recordMiss(): void {
    this.misses++
  }
  
  reset(): void {
    this.hits = 0
    this.misses = 0
  }
  
  getStats() {
    return {
      hits: this.hits,
      misses: this.misses,
      hitRate: this.hitRate,
      total: this.hits + this.misses
    }
  }
}

// å¯¼å‡ºå…¨å±€æŒ‡æ ‡
export const embeddingCacheMetrics = new EmbeddingCacheMetrics()
```

#### 2. ç¼“å­˜æ€§èƒ½æŒ‡æ ‡

```typescript
interface CachePerformanceMetrics {
  // å»¶è¿Ÿ
  cacheLatency: number          // ç¼“å­˜æŸ¥è¯¢å»¶è¿Ÿ (ms)
  embeddingLatency: number      // API è°ƒç”¨å»¶è¿Ÿ (ms)
  
  // åå
  cacheHits: number             // ç´¯è®¡å‘½ä¸­æ¬¡æ•°
  cacheMisses: number           // ç´¯è®¡æœªå‘½ä¸­æ¬¡æ•°
  
  // å­˜å‚¨
  cachedKeys: number            // å½“å‰ç¼“å­˜é”®æ•°é‡
  totalMemory: number           // æ€»å†…å­˜å ç”¨ (bytes)
}
```

#### 3. Axiom æ—¥å¿—ç»“æ„

```typescript
// ç¼“å­˜å‘½ä¸­æ—¥å¿—
logger.info('embedding_cache_hit', {
  cacheKey: 'qv:zhipu:...',
  queryLength: 15,
  latency: 5,  // ms
  provider: 'zhipu'
})

// ç¼“å­˜æœªå‘½ä¸­æ—¥å¿—
logger.info('embedding_cache_miss', {
  cacheKey: 'qv:zhipu:...',
  queryLength: 15,
  embeddingLatency: 380,  // ms
  provider: 'zhipu',
  cached: true  // å·²å†™å…¥ç¼“å­˜
})

// ç¼“å­˜é”™è¯¯æ—¥å¿—
logger.error('embedding_cache_error', {
  error: 'Redis connection failed',
  operation: 'get',
  fallback: 'LLM API'
})
```

### ç›‘æ§ Dashboard (Axiom Query)

```sql
-- ç¼“å­˜å‘½ä¸­ç‡ (è¿‡å»1å°æ—¶)
SELECT 
  COUNT(*) FILTER (WHERE event = 'embedding_cache_hit') AS hits,
  COUNT(*) FILTER (WHERE event = 'embedding_cache_miss') AS misses,
  (hits::float / (hits + misses)) * 100 AS hit_rate_percent
FROM logs
WHERE timestamp > now() - interval '1 hour'
  AND (event = 'embedding_cache_hit' OR event = 'embedding_cache_miss')

-- å¹³å‡å»¶è¿Ÿå¯¹æ¯”
SELECT
  AVG(latency) FILTER (WHERE event = 'embedding_cache_hit') AS cache_hit_latency,
  AVG(embeddingLatency) FILTER (WHERE event = 'embedding_cache_miss') AS api_latency
FROM logs
WHERE timestamp > now() - interval '1 hour'

-- ç¼“å­˜èŠ‚çœçš„ API è°ƒç”¨æ¬¡æ•°
SELECT COUNT(*) AS api_calls_saved
FROM logs
WHERE timestamp > now() - interval '1 day'
  AND event = 'embedding_cache_hit'
```

---

## ğŸ”§ å®ç°è®¾è®¡

### ä»£ç ç»“æ„

```
src/
â””â”€â”€ services/
    â””â”€â”€ rag/
        â”œâ”€â”€ queryVectorizer.ts         # ç°æœ‰ (éœ€ä¿®æ”¹)
        â”œâ”€â”€ embeddingCache.ts          # æ–°å¢ âœ¨
        â””â”€â”€ queryCacheService.ts       # ç°æœ‰ (ä¸å˜)
```

### embeddingCache.ts (æ–°å¢æœåŠ¡)

```typescript
/**
 * Query Embedding ç¼“å­˜æœåŠ¡
 * ç¼“å­˜æŸ¥è¯¢çš„å‘é‡è¡¨ç¤ºï¼Œå‡å°‘ LLM API è°ƒç”¨
 */

import { Redis } from '@upstash/redis'
import { createHash } from 'crypto'
import { llmConfig } from '@/config/llm.config'

/**
 * ç¼“å­˜é…ç½®
 */
const CACHE_CONFIG = {
  TTL: 3600,                    // 1å°æ—¶ (ç§’)
  KEY_PREFIX: 'qv',             // Query Vector
  PROVIDER: llmConfig.provider  // å½“å‰ LLM æä¾›å•†
} as const

/**
 * ç¼“å­˜æŒ‡æ ‡
 */
class EmbeddingCacheMetrics {
  private hits = 0
  private misses = 0

  recordHit(): void { this.hits++ }
  recordMiss(): void { this.misses++ }

  get hitRate(): number {
    const total = this.hits + this.misses
    return total === 0 ? 0 : (this.hits / total)
  }

  getStats() {
    return {
      hits: this.hits,
      misses: this.misses,
      hitRate: this.hitRate,
      total: this.hits + this.misses
    }
  }

  reset(): void {
    this.hits = 0
    this.misses = 0
  }
}

/**
 * Embedding ç¼“å­˜æœåŠ¡ç±»
 */
export class EmbeddingCacheService {
  private redis: Redis | null = null
  private metrics = new EmbeddingCacheMetrics()

  constructor() {
    // ä»…åœ¨é…ç½®äº† Redis æ—¶åˆå§‹åŒ–
    if (process.env.UPSTASH_REDIS_REST_URL && 
        process.env.UPSTASH_REDIS_REST_TOKEN) {
      try {
        this.redis = new Redis({
          url: process.env.UPSTASH_REDIS_REST_URL,
          token: process.env.UPSTASH_REDIS_REST_TOKEN
        })
        
        if (process.env.NODE_ENV === 'development') {
          console.log('[EmbeddingCache] Redis initialized successfully')
        }
      } catch (error) {
        console.warn('[EmbeddingCache] Failed to initialize Redis:', error)
      }
    } else {
      console.warn('[EmbeddingCache] Redis not configured, embedding caching disabled')
    }
  }

  /**
   * ç”Ÿæˆç¼“å­˜é”®
   * æ ¼å¼: qv:{provider}:{hash}
   */
  private generateCacheKey(query: string): string {
    // 1. å½’ä¸€åŒ–æŸ¥è¯¢
    const normalized = query
      .trim()
      .toLowerCase()
      .replace(/\s+/g, ' ')  // å¤šç©ºæ ¼å½’ä¸€åŒ–
    
    // 2. è®¡ç®— MD5 hash
    const hash = createHash('md5')
      .update(normalized, 'utf8')
      .digest('hex')
    
    // 3. ç”Ÿæˆç¼“å­˜é”®
    return `${CACHE_CONFIG.KEY_PREFIX}:${CACHE_CONFIG.PROVIDER}:${hash}`
  }

  /**
   * è·å–ç¼“å­˜çš„å‘é‡
   * @param query æŸ¥è¯¢é—®é¢˜
   * @returns ç¼“å­˜çš„å‘é‡ï¼Œä¸å­˜åœ¨åˆ™è¿”å› null
   */
  async get(query: string): Promise<number[] | null> {
    if (!this.redis) return null

    const startTime = Date.now()
    const cacheKey = this.generateCacheKey(query)

    try {
      const cached = await this.redis.get<number[]>(cacheKey)
      const latency = Date.now() - startTime

      if (cached) {
        // ç¼“å­˜å‘½ä¸­
        this.metrics.recordHit()
        
        if (process.env.NODE_ENV === 'development') {
          console.log('[EmbeddingCache] Cache HIT:', {
            cacheKey,
            queryLength: query.length,
            vectorDim: cached.length,
            latency: `${latency}ms`,
            hitRate: `${(this.metrics.hitRate * 100).toFixed(1)}%`
          })
        }

        return cached
      }

      // ç¼“å­˜æœªå‘½ä¸­
      this.metrics.recordMiss()
      
      if (process.env.NODE_ENV === 'development') {
        console.log('[EmbeddingCache] Cache MISS:', {
          cacheKey,
          queryLength: query.length,
          latency: `${latency}ms`,
          hitRate: `${(this.metrics.hitRate * 100).toFixed(1)}%`
        })
      }

      return null

    } catch (error) {
      console.warn('[EmbeddingCache] Failed to get cached embedding:', error)
      return null  // ç¼“å­˜é”™è¯¯ä¸å½±å“ä¸»æµç¨‹
    }
  }

  /**
   * ç¼“å­˜å‘é‡
   * @param query æŸ¥è¯¢é—®é¢˜
   * @param vector å‘é‡è¡¨ç¤º
   */
  async set(query: string, vector: number[]): Promise<void> {
    if (!this.redis) return

    const cacheKey = this.generateCacheKey(query)

    try {
      // ä½¿ç”¨ SETEX è®¾ç½®å¸¦ TTL çš„ç¼“å­˜
      await this.redis.setex(
        cacheKey,
        CACHE_CONFIG.TTL,
        JSON.stringify(vector)
      )

      if (process.env.NODE_ENV === 'development') {
        console.log('[EmbeddingCache] Cached embedding:', {
          cacheKey,
          vectorDim: vector.length,
          ttl: CACHE_CONFIG.TTL
        })
      }

    } catch (error) {
      console.warn('[EmbeddingCache] Failed to cache embedding:', error)
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    }
  }

  /**
   * æ¸…é™¤æä¾›å•†çš„æ‰€æœ‰ç¼“å­˜
   * ç”¨äº LLM æä¾›å•†åˆ‡æ¢æˆ–æ¨¡å‹å‡çº§
   */
  async invalidateProvider(provider: string = CACHE_CONFIG.PROVIDER): Promise<void> {
    if (!this.redis) return

    try {
      const pattern = `${CACHE_CONFIG.KEY_PREFIX}:${provider}:*`
      const keys = await this.redis.keys(pattern)

      if (keys.length > 0) {
        await this.redis.del(...keys)
        console.log(`[EmbeddingCache] Invalidated ${keys.length} keys for provider ${provider}`)
      }

    } catch (error) {
      console.warn('[EmbeddingCache] Failed to invalidate provider cache:', error)
    }
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
   */
  async getStats(): Promise<{
    enabled: boolean
    metrics: ReturnType<EmbeddingCacheMetrics['getStats']>
    redisKeys?: number
    estimatedMemory?: string
  }> {
    if (!this.redis) {
      return {
        enabled: false,
        metrics: this.metrics.getStats()
      }
    }

    try {
      const pattern = `${CACHE_CONFIG.KEY_PREFIX}:${CACHE_CONFIG.PROVIDER}:*`
      const keys = await this.redis.keys(pattern)
      const keyCount = keys.length
      const estimatedMemory = `~${(keyCount * 4.2 / 1024).toFixed(2)} MB`

      return {
        enabled: true,
        metrics: this.metrics.getStats(),
        redisKeys: keyCount,
        estimatedMemory
      }

    } catch (error) {
      console.warn('[EmbeddingCache] Failed to get cache stats:', error)
      return {
        enabled: true,
        metrics: this.metrics.getStats()
      }
    }
  }

  /**
   * æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨
   */
  isEnabled(): boolean {
    return this.redis !== null
  }

  /**
   * é‡ç½®ç¼“å­˜æŒ‡æ ‡
   */
  resetMetrics(): void {
    this.metrics.reset()
  }
}

// å¯¼å‡ºå•ä¾‹
export const embeddingCache = new EmbeddingCacheService()
```

### queryVectorizer.ts (ä¿®æ”¹)

```typescript
/**
 * æŸ¥è¯¢å‘é‡åŒ–æœåŠ¡
 * å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºå‘é‡ç”¨äºæ£€ç´¢
 * 
 * Story 4.2: æ·»åŠ  Embedding ç¼“å­˜æ”¯æŒ âœ¨
 */

import { LLMRepositoryFactory } from '@/infrastructure/llm/llm-repository.factory'
import { llmConfig, EMBEDDING_DIMENSION } from '@/config/llm.config'
import { embeddingCache } from './embeddingCache'  // âœ¨ æ–°å¢

export class QueryVectorizationError extends Error {
  constructor(message: string, public code: string) {
    super(message)
    this.name = 'QueryVectorizationError'
  }
}

export class QueryVectorizer {
  private llmRepo = LLMRepositoryFactory.create(llmConfig)

  /**
   * å‘é‡åŒ–æŸ¥è¯¢é—®é¢˜ (å¸¦ç¼“å­˜)
   * @param question ç”¨æˆ·é—®é¢˜(1-1000å­—ç¬¦)
   * @returns å‘é‡è¡¨ç¤º
   * @throws {QueryVectorizationError} å‘é‡åŒ–å¤±è´¥æˆ–è¶…æ—¶
   */
  async vectorizeQuery(question: string): Promise<number[]> {
    const startTime = Date.now()

    try {
      // è¾“å…¥éªŒè¯
      const trimmed = question.trim()
      if (!trimmed) {
        throw new QueryVectorizationError('Question cannot be empty', 'INVALID_INPUT')
      }
      
      if (trimmed.length > 1000) {
        throw new QueryVectorizationError('Question too long (max 1000 characters)', 'INVALID_INPUT')
      }

      // âœ¨ Story 4.2: å°è¯•ä»ç¼“å­˜è·å–
      const cachedVector = await embeddingCache.get(trimmed)
      
      if (cachedVector) {
        const elapsed = Date.now() - startTime
        
        if (process.env.NODE_ENV === 'development') {
          console.log('[QueryVectorizer] Using cached embedding:', {
            questionLength: trimmed.length,
            vectorDim: cachedVector.length,
            elapsed: `${elapsed}ms`,
            source: 'cache'
          })
        }

        return cachedVector
      }

      // ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ LLM API
      const vectors = await this.llmRepo.generateEmbeddings([trimmed])
      
      if (!vectors || vectors.length === 0) {
        throw new QueryVectorizationError('Empty embedding response', 'EMBEDDING_ERROR')
      }

      const vector = vectors[0]
      
      // éªŒè¯å‘é‡ç»´åº¦
      if (vector.length !== EMBEDDING_DIMENSION) {
        throw new QueryVectorizationError(
          `Invalid vector dimension: ${vector.length}, expected ${EMBEDDING_DIMENSION}`,
          'EMBEDDING_ERROR'
        )
      }

      // âœ¨ Story 4.2: å¼‚æ­¥å†™å…¥ç¼“å­˜ (ä¸é˜»å¡å“åº”)
      embeddingCache.set(trimmed, vector).catch(err => {
        console.warn('[QueryVectorizer] Failed to cache embedding:', err)
      })

      const elapsed = Date.now() - startTime

      if (process.env.NODE_ENV === 'development') {
        console.log('[QueryVectorizer] Query vectorized:', {
          questionLength: trimmed.length,
          vectorDim: vector.length,
          elapsed: `${elapsed}ms`,
          source: 'api',
          cached: true  // å·²å†™å…¥ç¼“å­˜
        })
      }

      return vector

    } catch (error) {
      const elapsed = Date.now() - startTime

      console.error('[QueryVectorizer] Query vectorization failed', {
        error: error instanceof Error ? error.message : String(error),
        elapsed: `${elapsed}ms`
      })

      // é”™è¯¯å¤„ç†é€»è¾‘ä¿æŒä¸å˜...
      if (error instanceof QueryVectorizationError) {
        throw error
      }

      const errorMessage = error instanceof Error ? error.message : String(error)
      
      if (errorMessage.includes('timeout') || errorMessage.includes('ETIMEDOUT')) {
        throw new QueryVectorizationError('Embedding request timeout', 'EMBEDDING_TIMEOUT')
      } else if (errorMessage.includes('quota') || errorMessage.includes('429')) {
        throw new QueryVectorizationError('API quota exceeded', 'QUOTA_EXCEEDED')
      } else {
        throw new QueryVectorizationError('Embedding generation failed', 'EMBEDDING_ERROR')
      }
    }
  }
}

// å¯¼å‡ºå•ä¾‹
export const queryVectorizer = new QueryVectorizer()
```

### ç›‘æ§ API ç«¯ç‚¹ (å¯é€‰)

```typescript
// src/app/api/monitoring/embedding-cache/route.ts

import { NextResponse } from 'next/server'
import { auth } from '@/lib/auth'
import { embeddingCache } from '@/services/rag/embeddingCache'

/**
 * GET /api/monitoring/embedding-cache
 * è·å– Embedding ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
 * 
 * ä»…ç®¡ç†å‘˜å¯è®¿é—®
 */
export async function GET() {
  // 1. è®¤è¯æ£€æŸ¥
  const session = await auth()
  if (!session?.user) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
  }

  // TODO: æ·»åŠ ç®¡ç†å‘˜æƒé™æ£€æŸ¥
  // if (session.user.role !== 'admin') {
  //   return NextResponse.json({ error: 'Forbidden' }, { status: 403 })
  // }

  // 2. è·å–ç¼“å­˜ç»Ÿè®¡
  const stats = await embeddingCache.getStats()

  return NextResponse.json({
    success: true,
    data: stats,
    timestamp: new Date().toISOString()
  })
}
```

---

## ğŸ“ˆ æ€§èƒ½å½±å“åˆ†æ

### é¢„æœŸæ€§èƒ½æå‡

**å‡è®¾**:
- ç¼“å­˜å‘½ä¸­ç‡: 60% (ä¿å®ˆä¼°è®¡)
- ç¼“å­˜æŸ¥è¯¢å»¶è¿Ÿ: 5ms (Redis)
- API è°ƒç”¨å»¶è¿Ÿ: 380ms (LLM Embedding)

**è®¡ç®—**:
```
åŠ æƒå¹³å‡å»¶è¿Ÿ = (å‘½ä¸­ç‡ Ã— ç¼“å­˜å»¶è¿Ÿ) + (æœªå‘½ä¸­ç‡ Ã— APIå»¶è¿Ÿ)
             = (0.6 Ã— 5ms) + (0.4 Ã— 380ms)
             = 3ms + 152ms
             = 155ms

æ€§èƒ½æå‡ = (380ms - 155ms) / 380ms = 59.2%
```

**æ€»æ£€ç´¢æ—¶é—´**:
```
å½“å‰: 380ms (å‘é‡åŒ–) + 240ms (æ£€ç´¢) = 620ms
ä¼˜åŒ–: 155ms (å‘é‡åŒ–) + 240ms (æ£€ç´¢) = 395ms

æ€»æå‡ = (620ms - 395ms) / 620ms = 36.3%
```

### æˆæœ¬èŠ‚çœ

**LLM API æˆæœ¬**:
- æ™ºè°±AI Embedding-2: Â¥0.0005/1K tokens
- å¹³å‡æŸ¥è¯¢: ~20 tokens
- å•æ¬¡è°ƒç”¨æˆæœ¬: ~Â¥0.00001

**ç¼“å­˜èŠ‚çœ** (60% å‘½ä¸­ç‡):
```
æ¯æ—¥æŸ¥è¯¢: 1000æ¬¡
ç¼“å­˜å‘½ä¸­: 600æ¬¡
èŠ‚çœæˆæœ¬: 600 Ã— Â¥0.00001 = Â¥0.006/å¤© = Â¥2.19/å¹´
```

**æ³¨æ„**: æˆæœ¬èŠ‚çœä¸æ˜¯ä¸»è¦æ”¶ç›Šï¼Œ**ç”¨æˆ·ä½“éªŒæå‡**æ‰æ˜¯æ ¸å¿ƒä»·å€¼ã€‚

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```typescript
// tests/unit/services/rag/embeddingCache.test.ts

describe('EmbeddingCacheService', () => {
  let cache: EmbeddingCacheService
  let mockRedis: jest.Mocked<Redis>

  beforeEach(() => {
    // Mock Redis
    mockRedis = {
      get: jest.fn(),
      setex: jest.fn(),
      keys: jest.fn(),
      del: jest.fn()
    } as any

    cache = new EmbeddingCacheService()
    cache['redis'] = mockRedis
  })

  describe('get', () => {
    it('åº”è¯¥è¿”å›ç¼“å­˜çš„å‘é‡', async () => {
      const query = 'ä»€ä¹ˆæ˜¯AI?'
      const vector = new Array(1024).fill(0.1)
      mockRedis.get.mockResolvedValue(vector)

      const result = await cache.get(query)

      expect(result).toEqual(vector)
      expect(mockRedis.get).toHaveBeenCalledWith(
        expect.stringContaining('qv:zhipu:')
      )
    })

    it('åº”è¯¥åœ¨ç¼“å­˜æœªå‘½ä¸­æ—¶è¿”å›null', async () => {
      mockRedis.get.mockResolvedValue(null)

      const result = await cache.get('æ–°é—®é¢˜')

      expect(result).toBeNull()
    })

    it('åº”è¯¥å½’ä¸€åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²', async () => {
      mockRedis.get.mockResolvedValue(null)

      await cache.get('ä»€ä¹ˆæ˜¯  AI ?')  // å¤šç©ºæ ¼
      await cache.get('ä»€ä¹ˆæ˜¯ ai ?')   // å°å†™

      // ä¸¤æ¬¡è°ƒç”¨åº”è¯¥ä½¿ç”¨ç›¸åŒçš„ç¼“å­˜é”®
      const calls = mockRedis.get.mock.calls
      expect(calls[0][0]).toBe(calls[1][0])
    })
  })

  describe('set', () => {
    it('åº”è¯¥ç¼“å­˜å‘é‡å¹¶è®¾ç½®TTL', async () => {
      const query = 'ä»€ä¹ˆæ˜¯AI?'
      const vector = new Array(1024).fill(0.1)

      await cache.set(query, vector)

      expect(mockRedis.setex).toHaveBeenCalledWith(
        expect.stringContaining('qv:zhipu:'),
        3600,  // TTL
        JSON.stringify(vector)
      )
    })

    it('åº”è¯¥åœ¨Rediså¤±è´¥æ—¶ä¸æŠ›å‡ºé”™è¯¯', async () => {
      mockRedis.setex.mockRejectedValue(new Error('Redis error'))

      await expect(
        cache.set('é—®é¢˜', [1, 2, 3])
      ).resolves.not.toThrow()
    })
  })

  describe('getStats', () => {
    it('åº”è¯¥è¿”å›ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯', async () => {
      // æ¨¡æ‹Ÿä¸€äº›ç¼“å­˜å‘½ä¸­
      mockRedis.get.mockResolvedValueOnce([1, 2, 3])
      await cache.get('query1')
      
      mockRedis.get.mockResolvedValueOnce(null)
      await cache.get('query2')

      mockRedis.keys.mockResolvedValue(['key1', 'key2'])

      const stats = await cache.getStats()

      expect(stats).toMatchObject({
        enabled: true,
        metrics: {
          hits: 1,
          misses: 1,
          hitRate: 0.5,
          total: 2
        },
        redisKeys: 2
      })
    })
  })
})
```

### é›†æˆæµ‹è¯•

```typescript
// tests/integration/rag/embedding-cache.test.ts

describe('Embedding Cache Integration', () => {
  it('åº”è¯¥å®Œæ•´æµ‹è¯•ç¼“å­˜æµç¨‹', async () => {
    const query = 'ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½?'

    // ç¬¬ä¸€æ¬¡è°ƒç”¨ - ç¼“å­˜æœªå‘½ä¸­
    const start1 = Date.now()
    const vector1 = await queryVectorizer.vectorizeQuery(query)
    const time1 = Date.now() - start1

    expect(vector1).toHaveLength(1024)
    expect(time1).toBeGreaterThan(300)  // åº”è¯¥è°ƒç”¨API

    // ç¬¬äºŒæ¬¡è°ƒç”¨ - ç¼“å­˜å‘½ä¸­
    const start2 = Date.now()
    const vector2 = await queryVectorizer.vectorizeQuery(query)
    const time2 = Date.now() - start2

    expect(vector2).toEqual(vector1)  // å‘é‡ç›¸åŒ
    expect(time2).toBeLessThan(50)    // åº”è¯¥ä»ç¼“å­˜è¿”å›
  })

  it('åº”è¯¥å¤„ç†å½’ä¸€åŒ–æŸ¥è¯¢', async () => {
    const queries = [
      'ä»€ä¹ˆæ˜¯AI?',
      'ä»€ä¹ˆæ˜¯AIï¼Ÿ',  // ä¸­æ–‡æ ‡ç‚¹
      'ä»€ä¹ˆæ˜¯  AI ?',  // å¤šç©ºæ ¼
      'ä»€ä¹ˆæ˜¯ ai ?'    // å°å†™
    ]

    // ç¬¬ä¸€æ¬¡è°ƒç”¨
    await queryVectorizer.vectorizeQuery(queries[0])

    // åç»­è°ƒç”¨åº”è¯¥éƒ½å‘½ä¸­ç¼“å­˜
    for (const query of queries.slice(1)) {
      const start = Date.now()
      await queryVectorizer.vectorizeQuery(query)
      const elapsed = Date.now() - start

      expect(elapsed).toBeLessThan(50)  // åº”è¯¥ä»ç¼“å­˜è¿”å›
    }
  })
})
```

### æ€§èƒ½æµ‹è¯•

```typescript
// tests/performance/embedding-cache.perf.ts

describe('Embedding Cache Performance', () => {
  it('åº”è¯¥è¾¾åˆ°ç›®æ ‡å‘½ä¸­ç‡ (>60%)', async () => {
    // æ¨¡æ‹ŸçœŸå®ç”¨æˆ·æŸ¥è¯¢åˆ†å¸ƒ
    const queries = [
      'ä»€ä¹ˆæ˜¯AI?',
      'ä»€ä¹ˆæ˜¯AIï¼Ÿ',  // é‡å¤
      'äººå·¥æ™ºèƒ½çš„å®šä¹‰',
      'ä»€ä¹ˆæ˜¯AI?',   // é‡å¤
      'AIçš„åº”ç”¨',
      'ä»€ä¹ˆæ˜¯AI?',   // é‡å¤
      'AI vs ML',
      'äººå·¥æ™ºèƒ½çš„å®šä¹‰',  // é‡å¤
    ]

    let cacheHits = 0
    let cacheMisses = 0

    for (const query of queries) {
      const start = Date.now()
      await queryVectorizer.vectorizeQuery(query)
      const elapsed = Date.now() - start

      if (elapsed < 50) {
        cacheHits++
      } else {
        cacheMisses++
      }
    }

    const hitRate = cacheHits / queries.length

    console.log(`Cache Hit Rate: ${(hitRate * 100).toFixed(1)}%`)
    console.log(`Hits: ${cacheHits}, Misses: ${cacheMisses}`)

    expect(hitRate).toBeGreaterThan(0.6)  // >60% å‘½ä¸­ç‡
  })

  it('åº”è¯¥æµ‹è¯•ç¼“å­˜æ€§èƒ½æå‡', async () => {
    const query = 'æµ‹è¯•æŸ¥è¯¢'
    
    // é¢„çƒ­ç¼“å­˜
    await queryVectorizer.vectorizeQuery(query)

    // æ€§èƒ½æµ‹è¯•
    const iterations = 100
    const start = Date.now()

    for (let i = 0; i < iterations; i++) {
      await queryVectorizer.vectorizeQuery(query)
    }

    const elapsed = Date.now() - start
    const avgLatency = elapsed / iterations

    console.log(`Average latency (cached): ${avgLatency.toFixed(2)}ms`)

    expect(avgLatency).toBeLessThan(10)  // åº”è¯¥ <10ms
  })
})
```

---

## ğŸš€ éƒ¨ç½²å’Œé…ç½®

### ç¯å¢ƒå˜é‡

**.env.local** (å·²å­˜åœ¨ï¼Œæ— éœ€ä¿®æ”¹):
```bash
# Redis é…ç½® (å·²é…ç½®)
UPSTASH_REDIS_REST_URL=https://your-redis.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-redis-token

# LLM é…ç½® (å·²é…ç½®)
LLM_PROVIDER=zhipu
ZHIPU_API_KEY=your-zhipu-api-key
```

### Upstash Redis é…ç½®

**å½“å‰é…ç½®**: å·²é…ç½® (Story 3.2)

**éªŒè¯**:
```bash
curl https://your-redis.upstash.io/ping \
  -H "Authorization: Bearer your-redis-token"

# é¢„æœŸè¾“å‡º: {"result":"PONG"}
```

### ç›‘æ§é…ç½®

**Axiom Dataset**: `doc-qa-system`  
**ç›‘æ§æŒ‡æ ‡**:
- `embedding_cache_hit`
- `embedding_cache_miss`
- `embedding_cache_error`

**å‘Šè­¦è§„åˆ™** (å»ºè®®):
1. ç¼“å­˜å‘½ä¸­ç‡ < 40% (24å°æ—¶çª—å£)
2. ç¼“å­˜é”™è¯¯ç‡ > 5%
3. Redis å†…å­˜ä½¿ç”¨ > 200MB

---

## ğŸ“š æ–‡æ¡£å’ŒçŸ¥è¯†ä¼ é€’

### å¼€å‘è€…æ–‡æ¡£

```markdown
# Query Embedding ç¼“å­˜ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

Query Embedding ç¼“å­˜è‡ªåŠ¨ç¼“å­˜æŸ¥è¯¢å‘é‡ï¼Œæ— éœ€ä¿®æ”¹è°ƒç”¨ä»£ç ã€‚

## å·¥ä½œåŸç†

1. **é€æ˜ç¼“å­˜**: `queryVectorizer.vectorizeQuery()` è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
2. **è‡ªåŠ¨å¤±æ•ˆ**: TTL 1å°æ—¶ï¼ŒRedis LRU è‡ªåŠ¨ç®¡ç†å†…å­˜
3. **é™çº§å‹å¥½**: ç¼“å­˜å¤±è´¥è‡ªåŠ¨å›é€€åˆ° API è°ƒç”¨

## ç›‘æ§

### æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡

```typescript
import { embeddingCache } from '@/services/rag/embeddingCache'

const stats = await embeddingCache.getStats()
console.log(stats)
// {
//   enabled: true,
//   metrics: {
//     hits: 150,
//     misses: 100,
//     hitRate: 0.6,
//     total: 250
//   },
//   redisKeys: 180,
//   estimatedMemory: '~0.76 MB'
// }
```

### Axiom æŸ¥è¯¢

```sql
-- ç¼“å­˜å‘½ä¸­ç‡
SELECT 
  (COUNT(*) FILTER (WHERE event = 'embedding_cache_hit')::float / 
   COUNT(*))::numeric(4,2) AS hit_rate
FROM logs
WHERE timestamp > now() - interval '1 hour'
```

## æ•…éšœæ’æŸ¥

### ç¼“å­˜æœªå¯ç”¨

**ç—‡çŠ¶**: æ‰€æœ‰æŸ¥è¯¢éƒ½è°ƒç”¨ API  
**æ£€æŸ¥**: 
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $UPSTASH_REDIS_REST_URL
echo $UPSTASH_REDIS_REST_TOKEN
```

### å‘½ä¸­ç‡ä½

**ç—‡çŠ¶**: å‘½ä¸­ç‡ < 40%  
**å¯èƒ½åŸå› **:
1. ç”¨æˆ·æŸ¥è¯¢éå¸¸å¤šæ ·åŒ– (æ­£å¸¸)
2. TTL è¿‡çŸ­ (æ£€æŸ¥é…ç½®)
3. Redis å†…å­˜ä¸è¶³ (æ£€æŸ¥ Upstash é…é¢)

### Redis é”™è¯¯

**ç—‡çŠ¶**: æ—¥å¿—ä¸­å‡ºç° Redis è¿æ¥é”™è¯¯  
**å½±å“**: æ— ï¼Œè‡ªåŠ¨é™çº§åˆ° API
**è§£å†³**: æ£€æŸ¥ Upstash æœåŠ¡çŠ¶æ€å’Œé…é¢
```

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] ç¼“å­˜é”®ç”Ÿæˆæ­£ç¡® (å½’ä¸€åŒ– + MD5)
- [ ] ç¼“å­˜å‘½ä¸­æ—¶è¿”å›ç¼“å­˜å‘é‡
- [ ] ç¼“å­˜æœªå‘½ä¸­æ—¶è°ƒç”¨ API å¹¶ç¼“å­˜
- [ ] TTL 1å°æ—¶ç”Ÿæ•ˆ
- [ ] ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

### æ€§èƒ½éªŒæ”¶

- [ ] ç¼“å­˜å‘½ä¸­å»¶è¿Ÿ < 10ms
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 60% (çœŸå®æµé‡)
- [ ] æ€»æ£€ç´¢æ—¶é—´å¹³å‡æå‡ > 50%
- [ ] P95 æ£€ç´¢æ—¶é—´ < 400ms

### è´¨é‡éªŒæ”¶

- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•éªŒè¯è¾¾æ ‡
- [ ] æ–‡æ¡£å®Œæ•´

### ç›‘æ§éªŒæ”¶

- [ ] ç¼“å­˜å‘½ä¸­ç‡ Dashboard å¯ç”¨
- [ ] ç¼“å­˜é”™è¯¯å‘Šè­¦é…ç½®
- [ ] Axiom æ—¥å¿—æ­£å¸¸ä¸ŠæŠ¥

---

## ğŸ”„ æœªæ¥ä¼˜åŒ–æ–¹å‘

### Phase 2: æ™ºèƒ½é¢„çƒ­

```typescript
/**
 * çƒ­é—¨æŸ¥è¯¢è‡ªåŠ¨é¢„çƒ­
 * å®šæœŸåˆ†æ Axiom æ—¥å¿—ï¼Œé¢„çƒ­é«˜é¢‘æŸ¥è¯¢
 */
async function preheatPopularQueries() {
  // ä» Axiom è·å– Top 100 æŸ¥è¯¢
  const popularQueries = await fetchPopularQueries(100)
  
  // å¹¶å‘é¢„çƒ­
  await Promise.all(
    popularQueries.map(q => queryVectorizer.vectorizeQuery(q))
  )
}
```

### Phase 3: å¤šçº§ç¼“å­˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L1: Memory â”‚  10ms TTL, 100 æ¡
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L2: Redis  â”‚  1h TTL, 10000 æ¡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 4: è¯­ä¹‰ç¼“å­˜

```typescript
/**
 * è¯­ä¹‰ç›¸ä¼¼æŸ¥è¯¢å…±äº«ç¼“å­˜
 * "ä»€ä¹ˆæ˜¯AI?" å’Œ "AIæ˜¯ä»€ä¹ˆ?" åº”è¯¥å…±äº«ç¼“å­˜
 */
async function semanticCacheKey(query: string): Promise<string> {
  // 1. è¯­ä¹‰å‘é‡åŒ–
  const semanticVector = await semanticEncoder.encode(query)
  
  // 2. æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å·²ç¼“å­˜æŸ¥è¯¢ (cosine > 0.95)
  const similarCached = await findSimilarCachedQuery(semanticVector, 0.95)
  
  if (similarCached) {
    return similarCached.cacheKey  // å¤ç”¨ç¼“å­˜
  }
  
  return generateNewCacheKey(query)
}
```

---

## ğŸ“ è”ç³»å’Œæ”¯æŒ

**æ¶æ„å¸ˆ**: Winston  
**æ–‡æ¡£**: `docs/architecture/query-embedding-cache-design.md`  
**ä»£ç **: `src/services/rag/embeddingCache.ts`  
**æµ‹è¯•**: `tests/unit/services/rag/embeddingCache.test.ts`

**é—®é¢˜åé¦ˆ**: 
- Slack: `#epic-4-quality`
- GitHub Issue: Tag `@Winston` + `performance`

---

**æ¶æ„è®¾è®¡çŠ¶æ€**: âœ… **Complete**  
**å®æ–½å°±ç»ª**: âœ… **Ready**  
**åˆ›å»ºæ—¥æœŸ**: 2025-01-10  
**å®¡æ ¸äºº**: å¾… Dev + QA å®¡æ ¸




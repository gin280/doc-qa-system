/**
 * RAGæ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯•
 * Story 3.2 - éªŒè¯æ€§èƒ½ç›®æ ‡
 * 
 * æ€§èƒ½ç›®æ ‡ï¼š
 * - å‘é‡åŒ–å»¶è¿Ÿ < 300ms (P95)
 * - å‘é‡æ£€ç´¢å»¶è¿Ÿ < 200ms (P95)
 * - ç«¯åˆ°ç«¯å»¶è¿Ÿ < 500ms (P95)
 * - ç¼“å­˜å‘½ä¸­ç‡ > 30%
 */

import { describe, it, expect, beforeAll, afterAll } from '@jest/globals'
import { db } from '@/lib/db'
import { documents, users, documentChunks } from '../../drizzle/schema'
import { eq } from 'drizzle-orm'
import { nanoid } from 'nanoid'
import { retrievalService } from '@/services/rag/retrievalService'
import { queryVectorizer } from '@/services/rag/queryVectorizer'
import { VectorRepositoryFactory } from '@/infrastructure/vector/vector-repository.factory'
import { vectorConfig } from '@/config/vector.config'

/**
 * è®¡ç®—ç™¾åˆ†ä½æ•°
 */
function percentile(arr: number[], p: number): number {
  const sorted = [...arr].sort((a, b) => a - b)
  const index = Math.ceil(sorted.length * p) - 1
  return sorted[index]
}

/**
 * æ€§èƒ½æµ‹è¯•ç»“æœç±»å‹
 */
interface BenchmarkResult {
  p50: number
  p95: number
  p99: number
  avg: number
  min: number
  max: number
  samples: number
}

/**
 * è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
 */
async function runBenchmark(
  testFn: () => Promise<void>,
  iterations: number = 20
): Promise<BenchmarkResult> {
  const latencies: number[] = []
  
  // é¢„çƒ­ï¼ˆæ’é™¤å†·å¯åŠ¨å½±å“ï¼‰
  for (let i = 0; i < 3; i++) {
    await testFn()
  }
  
  // æ­£å¼æµ‹è¯•
  for (let i = 0; i < iterations; i++) {
    const start = performance.now()
    await testFn()
    latencies.push(performance.now() - start)
  }
  
  return {
    p50: percentile(latencies, 0.5),
    p95: percentile(latencies, 0.95),
    p99: percentile(latencies, 0.99),
    avg: latencies.reduce((a, b) => a + b) / latencies.length,
    min: Math.min(...latencies),
    max: Math.max(...latencies),
    samples: latencies.length
  }
}

describe('RAG Retrieval Performance Benchmarks', () => {
  let testUserId: string
  let testDocumentId: string

  beforeAll(async () => {
    testUserId = nanoid()
    testDocumentId = nanoid()
    
    // Create test user
    await db.insert(users).values({
      id: testUserId,
      email: 'perf-test@test.com',
      name: 'Performance Test User'
    })
    
    // Create test document with READY status
    await db.insert(documents).values({
      id: testDocumentId,
      userId: testUserId,
      filename: 'performance-test.pdf',
      fileSize: 1024 * 500, // 500KB
      fileType: 'application/pdf',
      storagePath: `documents/${testUserId}/${testDocumentId}.pdf`,
      status: 'READY',
      chunksCount: 50, // More chunks for realistic performance test
      contentLength: 50000,
      uploadedAt: new Date()
    })
    
    // Create 50 test chunks
    const chunks = []
    for (let i = 0; i < 50; i++) {
      chunks.push({
        id: `perf-chunk-${i}`,
        documentId: testDocumentId,
        chunkIndex: i,
        content: `Performance test chunk ${i}. This is sample content about various topics including React, TypeScript, Next.js, and web development best practices.`,
        embeddingId: `perf-chunk-${i}`,
        metadata: {
          pageNumber: Math.floor(i / 5) + 1,
          section: `Section ${Math.floor(i / 10)}`
        }
      })
    }
    await db.insert(documentChunks).values(chunks)
  })

  afterAll(async () => {
    // Cleanup
    await db.delete(documentChunks).where(eq(documentChunks.documentId, testDocumentId))
    await db.delete(documents).where(eq(documents.id, testDocumentId))
    await db.delete(users).where(eq(users.id, testUserId))
  })

  // ============================================================================
  // PERF-001: æŸ¥è¯¢å‘é‡åŒ–æ€§èƒ½åŸºå‡†
  // ============================================================================
  describe('PERF-001: Query Vectorization Latency', () => {
    it('å‘é‡åŒ–å»¶è¿Ÿåº”è¯¥ < 300ms (P95)', async () => {
      const testQuery = 'What is React and how does it work?'
      
      const result = await runBenchmark(async () => {
        await queryVectorizer.vectorizeQuery(testQuery)
      }, 20)
      
      console.log('\nğŸ“Š Query Vectorization Performance:')
      console.log(`  P50: ${result.p50.toFixed(2)}ms`)
      console.log(`  P95: ${result.p95.toFixed(2)}ms`)
      console.log(`  P99: ${result.p99.toFixed(2)}ms`)
      console.log(`  Avg: ${result.avg.toFixed(2)}ms`)
      console.log(`  Range: ${result.min.toFixed(2)}ms - ${result.max.toFixed(2)}ms`)
      
      // éªŒè¯æ€§èƒ½ç›®æ ‡
      expect(result.p95).toBeLessThan(300)
      
      // è®°å½•åŸºçº¿æ•°æ®
      recordPerformanceBaseline('query-vectorization', result)
    })
  })

  // ============================================================================
  // PERF-002: å‘é‡æ£€ç´¢æ€§èƒ½åŸºå‡†
  // ============================================================================
  describe('PERF-002: Vector Search Latency', () => {
    it('å‘é‡æ£€ç´¢å»¶è¿Ÿåº”è¯¥ < 200ms (P95)', async () => {
      // ç”Ÿæˆæµ‹è¯•å‘é‡
      const testVector = await queryVectorizer.vectorizeQuery('test query')
      const vectorRepo = VectorRepositoryFactory.create(vectorConfig)
      
      const result = await runBenchmark(async () => {
        await vectorRepo.search(testVector, {
          topK: 5,
          minScore: 0.3,
          filter: { documentId: testDocumentId, userId: testUserId }
        })
      }, 20)
      
      console.log('\nğŸ“Š Vector Search Performance:')
      console.log(`  P50: ${result.p50.toFixed(2)}ms`)
      console.log(`  P95: ${result.p95.toFixed(2)}ms`)
      console.log(`  P99: ${result.p99.toFixed(2)}ms`)
      console.log(`  Avg: ${result.avg.toFixed(2)}ms`)
      
      // éªŒè¯æ€§èƒ½ç›®æ ‡
      expect(result.p95).toBeLessThan(200)
      
      recordPerformanceBaseline('vector-search', result)
    })
  })

  // ============================================================================
  // PERF-003: ç«¯åˆ°ç«¯æ£€ç´¢æ€§èƒ½åŸºå‡†
  // ============================================================================
  describe('PERF-003: End-to-End Retrieval Latency', () => {
    it('ç«¯åˆ°ç«¯æ£€ç´¢å»¶è¿Ÿåº”è¯¥ < 500ms (P95)', async () => {
      const testQuery = 'What is React Hooks and how to use useState?'
      
      const result = await runBenchmark(async () => {
        await retrievalService.retrieveContext(
          testQuery,
          testDocumentId,
          testUserId,
          {
            topK: 5,
            minScore: 0.3,
            useCache: false // ç¦ç”¨ç¼“å­˜ä»¥æµ‹è¯•çº¯æ£€ç´¢æ€§èƒ½
          }
        )
      }, 20)
      
      console.log('\nğŸ“Š End-to-End Retrieval Performance:')
      console.log(`  P50: ${result.p50.toFixed(2)}ms`)
      console.log(`  P95: ${result.p95.toFixed(2)}ms`)
      console.log(`  P99: ${result.p99.toFixed(2)}ms`)
      console.log(`  Avg: ${result.avg.toFixed(2)}ms`)
      
      // éªŒè¯æ€§èƒ½ç›®æ ‡
      expect(result.p95).toBeLessThan(500)
      
      recordPerformanceBaseline('end-to-end-retrieval', result)
    })
  })

  // ============================================================================
  // PERF-004: ç¼“å­˜æ€§èƒ½éªŒè¯
  // ============================================================================
  describe('PERF-004: Cache Hit Rate and Performance', () => {
    it('ç¼“å­˜å‘½ä¸­åº”è¯¥æ˜¾è‘—æå‡æ€§èƒ½', async () => {
      const testQuery = 'Cache performance test query'
      
      // ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆæœªç¼“å­˜ï¼‰
      const uncachedResult = await runBenchmark(async () => {
        await retrievalService.retrieveContext(
          testQuery,
          testDocumentId,
          testUserId,
          { useCache: true }
        )
      }, 1) // ä»…1æ¬¡ä»¥è®¾ç½®ç¼“å­˜
      
      // ç­‰å¾…ç¼“å­˜å†™å…¥å®Œæˆ
      await new Promise(resolve => setTimeout(resolve, 100))
      
      // ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
      const cachedResult = await runBenchmark(async () => {
        await retrievalService.retrieveContext(
          testQuery,
          testDocumentId,
          testUserId,
          { useCache: true }
        )
      }, 10)
      
      console.log('\nğŸ“Š Cache Performance Comparison:')
      console.log(`  Uncached P95: ${uncachedResult.p95.toFixed(2)}ms`)
      console.log(`  Cached P95: ${cachedResult.p95.toFixed(2)}ms`)
      console.log(`  Improvement: ${((1 - cachedResult.p95 / uncachedResult.p95) * 100).toFixed(1)}%`)
      
      // ç¼“å­˜åº”è¯¥æ˜¾è‘—æå‡æ€§èƒ½ï¼ˆè‡³å°‘å¿«30%ï¼‰
      expect(cachedResult.p95).toBeLessThan(uncachedResult.p95 * 0.7)
    })

    it('ç¼“å­˜å‘½ä¸­ç‡åº”è¯¥ > 30%', async () => {
      const queries = [
        'What is React?',
        'How to use useState?',
        'What is TypeScript?',
        'How to use Next.js?',
        'What is Tailwind CSS?'
      ]
      
      let cacheHits = 0
      let totalRequests = 0
      
      // æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œ5æ¬¡
      for (const query of queries) {
        for (let i = 0; i < 5; i++) {
          const result = await retrievalService.retrieveContext(
            query,
            testDocumentId,
            testUserId,
            { useCache: true }
          )
          
          if (result.cached) {
            cacheHits++
          }
          totalRequests++
          
          // ç»™ç¼“å­˜å†™å…¥ä¸€ç‚¹æ—¶é—´
          if (i === 0) {
            await new Promise(resolve => setTimeout(resolve, 50))
          }
        }
      }
      
      const hitRate = (cacheHits / totalRequests) * 100
      
      console.log('\nğŸ“Š Cache Hit Rate:')
      console.log(`  Total Requests: ${totalRequests}`)
      console.log(`  Cache Hits: ${cacheHits}`)
      console.log(`  Hit Rate: ${hitRate.toFixed(1)}%`)
      
      // éªŒè¯ç¼“å­˜å‘½ä¸­ç‡ç›®æ ‡
      // æœŸæœ›ï¼šç¬¬2-5æ¬¡è°ƒç”¨åº”è¯¥å‘½ä¸­ç¼“å­˜ï¼ˆç†è®º80%ï¼‰
      expect(hitRate).toBeGreaterThan(30)
    })
  })

  // ============================================================================
  // PERF-005: å¹¶å‘æ€§èƒ½æµ‹è¯•
  // ============================================================================
  describe('PERF-005: Concurrent Request Performance', () => {
    it('åº”è¯¥å¤„ç†10ä¸ªå¹¶å‘è¯·æ±‚', async () => {
      const concurrency = 10
      const latencies: number[] = []
      
      const promises = Array.from({ length: concurrency }, async (_, i) => {
        const start = performance.now()
        await retrievalService.retrieveContext(
          `Concurrent test query ${i}`,
          testDocumentId,
          testUserId,
          { useCache: false }
        )
        latencies.push(performance.now() - start)
      })
      
      await Promise.all(promises)
      
      const avgLatency = latencies.reduce((a, b) => a + b) / latencies.length
      const maxLatency = Math.max(...latencies)
      
      console.log('\nğŸ“Š Concurrent Performance (10 requests):')
      console.log(`  Avg Latency: ${avgLatency.toFixed(2)}ms`)
      console.log(`  Max Latency: ${maxLatency.toFixed(2)}ms`)
      console.log(`  Min Latency: ${Math.min(...latencies).toFixed(2)}ms`)
      
      // å¹¶å‘ä¸‹å»¶è¿Ÿåº”è¯¥åˆç†å¢åŠ ï¼Œä½†ä¸åº”è¯¥çº¿æ€§å¢é•¿
      expect(avgLatency).toBeLessThan(1000) // å¹³å‡ < 1ç§’
      expect(maxLatency).toBeLessThan(2000) // æœ€å¤§ < 2ç§’
    })
  })
})

/**
 * è®°å½•æ€§èƒ½åŸºçº¿æ•°æ®
 * ç”¨äºåç»­æ€§èƒ½å›å½’æµ‹è¯•
 */
function recordPerformanceBaseline(name: string, result: BenchmarkResult) {
  // TODO: å°†åŸºçº¿æ•°æ®æŒä¹…åŒ–åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“
  // å¯ä»¥ç”¨äºåç»­çš„æ€§èƒ½å›å½’æµ‹è¯•
  const baseline = {
    name,
    timestamp: new Date().toISOString(),
    result,
    environment: {
      node: process.version,
      platform: process.platform
    }
  }
  
  // å¼€å‘æ¨¡å¼ä¸‹è¾“å‡ºåˆ°æ§åˆ¶å°
  if (process.env.NODE_ENV === 'development') {
    console.log(`\nğŸ’¾ Performance Baseline Recorded: ${name}`)
  }
}

/**
 * ä½¿ç”¨è¯´æ˜ï¼š
 * 
 * 1. è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•ï¼š
 *    npm test -- tests/performance/rag-retrieval.benchmark.ts
 * 
 * 2. æ€§èƒ½åŸºå‡†æµ‹è¯•éœ€è¦ï¼š
 *    - çœŸå®çš„æ•°æ®åº“ç¯å¢ƒï¼ˆPostgreSQL + pgvectorï¼‰
 *    - LLM API keyï¼ˆç”¨äºçœŸå®çš„å‘é‡åŒ–ï¼‰
 *    - Redisï¼ˆå¯é€‰ï¼Œç”¨äºç¼“å­˜æµ‹è¯•ï¼‰
 * 
 * 3. æ€§èƒ½ç›®æ ‡éªŒè¯ï¼š
 *    - æŸ¥è¯¢å‘é‡åŒ–: P95 < 300ms
 *    - å‘é‡æ£€ç´¢: P95 < 200ms
 *    - ç«¯åˆ°ç«¯: P95 < 500ms
 *    - ç¼“å­˜å‘½ä¸­ç‡: > 30%
 * 
 * 4. æ³¨æ„äº‹é¡¹ï¼š
 *    - æ€§èƒ½å—ç½‘ç»œã€æ•°æ®åº“è´Ÿè½½ç­‰å› ç´ å½±å“
 *    - å»ºè®®åœ¨ç¨³å®šç¯å¢ƒä¸‹å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
 *    - å¯ä»¥æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´æ€§èƒ½ç›®æ ‡
 * 
 * 5. æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š
 *    - å¦‚æœå‘é‡åŒ–æ…¢ï¼šè€ƒè™‘ä½¿ç”¨æ›´å¿«çš„embeddingæ¨¡å‹
 *    - å¦‚æœæ£€ç´¢æ…¢ï¼šä¼˜åŒ–pgvectorç´¢å¼•å‚æ•°
 *    - å¦‚æœç¼“å­˜å‘½ä¸­ç‡ä½ï¼šä¼˜åŒ–æŸ¥è¯¢è§„èŒƒåŒ–é€»è¾‘
 */
